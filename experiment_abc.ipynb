{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61b7d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lr_scheduler import CosineLRScheduler\n",
    "\n",
    "try:\n",
    "    from eegdash.dataset import EEGChallengeDataset\n",
    "    from eegdash.hbn.windows import (\n",
    "        annotate_trials_with_target,\n",
    "        add_aux_anchors,\n",
    "        add_extras_columns,\n",
    "        keep_only_recordings_with,\n",
    "    )\n",
    "except Exception as e:\n",
    "    EEGChallengeDataset = None\n",
    "\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_windows_from_events\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "import torch.nn as nn\n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5280edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"LOL_DATASET/LOL_DATASET/HBN_DATA_FULL/\"\n",
    "RELEASES = [\"R1\", \"R2\", \"R3\"]\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b0b68ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=214725;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=411936;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=169652;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=917794;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=798069;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=439694;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dataset = []\n",
    "for rel in RELEASES:\n",
    "    name_folder = f\"{rel}_mini_L100_bdf\" \n",
    "    cache_dir = Path(DATA_PATH) / name_folder \n",
    "\n",
    "    dataset = EEGChallengeDataset(\n",
    "        cache_dir = cache_dir,\n",
    "        task = \"contrastChangeDetection\",\n",
    "        mini = True,\n",
    "        download = False,\n",
    "        release = rel\n",
    "    )\n",
    "\n",
    "    all_dataset.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82683afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7522500"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset = BaseConcatDataset(all_dataset)\n",
    "len(all_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf160ee3",
   "metadata": {},
   "source": [
    "Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c799b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_LENS_S = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8eedbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_offline_preprocessors():\n",
    "    return [\n",
    "        Preprocessor(annotate_trials_with_target, \n",
    "                     target_field = \"rt_from_stimulus\", \n",
    "                     epoch_length = EPOCH_LENS_S, \n",
    "                     require_stimulus = True, \n",
    "                     require_response = True, \n",
    "                     apply_on_array = False),\n",
    "        Preprocessor(add_aux_anchors, apply_on_array=False),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c1264",
   "metadata": {},
   "source": [
    "This case we don't need to save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01da0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n"
     ]
    }
   ],
   "source": [
    "preproc_dir = Path(\"preprocessed_dataset\")\n",
    "preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "list_windows = []\n",
    "\n",
    "ANCHOR = \"stimulus_anchor\"\n",
    "SHIFT_AFTER_STIM = 0.5\n",
    "WINDOW_LEN = 2.0\n",
    "SFREQ = 100\n",
    "\n",
    "preproc = build_offline_preprocessors()\n",
    "\n",
    "for i, dataset in enumerate(all_dataset):\n",
    "    preprocess(dataset, preproc, n_jobs = -1)\n",
    "\n",
    "    dataset = keep_only_recordings_with(ANCHOR, dataset)\n",
    "    windows = create_windows_from_events(\n",
    "        dataset, \n",
    "        mapping = {ANCHOR: 0},\n",
    "        trial_start_offset_samples = int(SHIFT_AFTER_STIM * SFREQ),                 # +0.5 s\n",
    "        trial_stop_offset_samples = int((SHIFT_AFTER_STIM + WINDOW_LEN) * SFREQ),   # +2.5 s\n",
    "        window_size_samples = int(WINDOW_LEN * SFREQ),\n",
    "        window_stride_samples = SFREQ,\n",
    "        preload=True,\n",
    "    )\n",
    "\n",
    "    windows = add_extras_columns(\n",
    "        windows,\n",
    "        dataset,\n",
    "        desc=ANCHOR,\n",
    "        keys=(\"target\", \"rt_from_stimulus\", \"rt_from_trialstart\",\n",
    "              \"stimulus_onset\", \"response_onset\", \"correct\", \"response_type\")\n",
    "    )\n",
    "\n",
    "    list_windows.append(windows)\n",
    "\n",
    "    save_path = preproc_dir / f\"{RELEASES[i]}_windows.pkl\"\n",
    "    joblib.dump(windows, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a02c1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_windows = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    load_path = preproc_dir / f\"{rel}_windows.pkl\"\n",
    "    windows = joblib.load(load_path)\n",
    "    load_windows.append(windows)\n",
    "\n",
    "all_windows = BaseConcatDataset(load_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a626c43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_window_in_trial</th>\n",
       "      <th>i_start_in_trial</th>\n",
       "      <th>i_stop_in_trial</th>\n",
       "      <th>target</th>\n",
       "      <th>rt_from_stimulus</th>\n",
       "      <th>rt_from_trialstart</th>\n",
       "      <th>stimulus_onset</th>\n",
       "      <th>response_onset</th>\n",
       "      <th>correct</th>\n",
       "      <th>response_type</th>\n",
       "      <th>...</th>\n",
       "      <th>thepresent</th>\n",
       "      <th>diaryofawimpykid</th>\n",
       "      <th>contrastchangedetection_1</th>\n",
       "      <th>contrastchangedetection_2</th>\n",
       "      <th>contrastchangedetection_3</th>\n",
       "      <th>surroundsupp_1</th>\n",
       "      <th>surroundsupp_2</th>\n",
       "      <th>seqlearning6target</th>\n",
       "      <th>seqlearning8target</th>\n",
       "      <th>symbolsearch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4278</td>\n",
       "      <td>4478</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>4.93</td>\n",
       "      <td>42.284</td>\n",
       "      <td>44.414</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4798</td>\n",
       "      <td>4998</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.96</td>\n",
       "      <td>4.76</td>\n",
       "      <td>47.484</td>\n",
       "      <td>49.444</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5478</td>\n",
       "      <td>5678</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.42</td>\n",
       "      <td>54.284</td>\n",
       "      <td>56.304</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6318</td>\n",
       "      <td>6518</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>7.72</td>\n",
       "      <td>62.684</td>\n",
       "      <td>64.404</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6838</td>\n",
       "      <td>7038</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>67.884</td>\n",
       "      <td>69.684</td>\n",
       "      <td>1</td>\n",
       "      <td>left_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_window_in_trial  i_start_in_trial  i_stop_in_trial  target  \\\n",
       "0                  0              4278             4478    2.13   \n",
       "1                  0              4798             4998    1.96   \n",
       "2                  0              5478             5678    2.02   \n",
       "3                  0              6318             6518    1.72   \n",
       "4                  0              6838             7038     1.8   \n",
       "\n",
       "   rt_from_stimulus  rt_from_trialstart  stimulus_onset  response_onset  \\\n",
       "0              2.13                4.93          42.284          44.414   \n",
       "1              1.96                4.76          47.484          49.444   \n",
       "2              2.02                6.42          54.284          56.304   \n",
       "3              1.72                7.72          62.684          64.404   \n",
       "4               1.8                 4.6          67.884          69.684   \n",
       "\n",
       "   correct      response_type  ... thepresent diaryofawimpykid  \\\n",
       "0        1  right_buttonPress  ...  available        available   \n",
       "1        1  right_buttonPress  ...  available        available   \n",
       "2        1  right_buttonPress  ...  available        available   \n",
       "3        1  right_buttonPress  ...  available        available   \n",
       "4        1   left_buttonPress  ...  available        available   \n",
       "\n",
       "  contrastchangedetection_1  contrastchangedetection_2  \\\n",
       "0                 available                  available   \n",
       "1                 available                  available   \n",
       "2                 available                  available   \n",
       "3                 available                  available   \n",
       "4                 available                  available   \n",
       "\n",
       "  contrastchangedetection_3 surroundsupp_1  surroundsupp_2 seqlearning6target  \\\n",
       "0                 available      available       available        unavailable   \n",
       "1                 available      available       available        unavailable   \n",
       "2                 available      available       available        unavailable   \n",
       "3                 available      available       available        unavailable   \n",
       "4                 available      available       available        unavailable   \n",
       "\n",
       "  seqlearning8target  symbolsearch  \n",
       "0          available     available  \n",
       "1          available     available  \n",
       "2          available     available  \n",
       "3          available     available  \n",
       "4          available     available  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_windows.get_metadata().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d44240",
   "metadata": {},
   "source": [
    "#### Spliting the train test valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5b6d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = all_windows.get_metadata()\n",
    "subjects = list(meta['subject'].unique())\n",
    "\n",
    "valid_frac = 0.1\n",
    "test_frac = 0.1\n",
    "seed = 2025\n",
    "\n",
    "train_subj, valid_test_subject = train_test_split(subjects, test_size=(valid_frac + test_frac), random_state=check_random_state(seed), shuffle=True)\n",
    "valid_subj, test_subj = train_test_split(valid_test_subject, test_size=test_frac/(valid_frac+test_frac), random_state=check_random_state(seed+1), shuffle=True)\n",
    "\n",
    "subject_split = windows.split(\"subject\")\n",
    "train_sets = [ds for subj, ds in subject_split.items() if subj in train_subj]\n",
    "valid_sets = [ds for subj, ds in subject_split.items() if subj in valid_subj]\n",
    "test_sets = [ds for subj, ds in subject_split.items() if subj in test_subj]\n",
    "\n",
    "train_ds = BaseConcatDataset(train_sets)\n",
    "valid_ds = BaseConcatDataset(valid_sets)\n",
    "test_ds = BaseConcatDataset(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ddada97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "134\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(valid_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c8d00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastChangeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, braindecode_dataset):\n",
    "        self.dataset = braindecode_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y, _ = self.dataset[idx]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "train_dataset = ContrastChangeDataset(train_ds)\n",
    "valid_dataset = ContrastChangeDataset(valid_ds)\n",
    "test_dataset = ContrastChangeDataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49f66893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2222e-05,  5.1986e-06,  5.3049e-06,  ..., -8.8720e-07,\n",
       "           7.3418e-07, -9.9474e-07],\n",
       "         [ 1.1537e-05,  5.4671e-06,  5.5437e-06,  ..., -6.2149e-07,\n",
       "           1.2688e-06,  3.0214e-07],\n",
       "         [ 1.3410e-05,  6.8182e-06,  5.9050e-06,  ...,  8.5317e-07,\n",
       "           1.7593e-06,  8.2808e-07],\n",
       "         ...,\n",
       "         [-8.4166e-06, -1.0888e-05, -9.3056e-06,  ...,  6.8735e-06,\n",
       "           3.1253e-06,  1.5513e-06],\n",
       "         [-1.2049e-05, -1.4262e-05, -1.3558e-05,  ...,  9.3226e-06,\n",
       "           5.4775e-06,  2.9852e-06],\n",
       "         [ 5.0000e-13,  5.0000e-13,  5.0000e-13,  ...,  5.0000e-13,\n",
       "           5.0000e-13,  5.0000e-13]]),\n",
       " tensor([1.9580]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = train_dataset[0]\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4315bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f622c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 129, 200]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "first_batch[0].shape, first_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28971512",
   "metadata": {},
   "source": [
    "Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd4945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/eeg_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "\n",
    "class FinetuneJEPA(nn.Module):\n",
    "    \"\"\"Simple wrapper: EegMambaJEPA backbone -> linear regression head.\"\"\"\n",
    "    def __init__(self, \n",
    "                 n_chans: int = 129, \n",
    "                 d_model: int = 256, \n",
    "                 n_layer: int = 8, \n",
    "                 patch_size: int = 10\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.backbone = EegMambaJEPA(\n",
    "            d_model=d_model, \n",
    "            n_layer=n_layer, \n",
    "            n_channels=n_chans, \n",
    "            patch_size=patch_size\n",
    "            )\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, C, T)\n",
    "        z = self.backbone(x)  # (B, d_model)\n",
    "        out = self.head(z)    # (B, 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2605e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = FinetuneJEPA(n_chans=129, d_model=256, n_layer=8, patch_size=10)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31e1ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['target_model.cls_token', 'target_model.patch_embed.proj.weight', 'target_model.patch_embed.proj.bias', 'target_model.mamba_blocks.0.in_proj.weight', 'target_model.mamba_blocks.0.conv1d.weight', 'target_model.mamba_blocks.0.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.A_log', 'target_model.mamba_blocks.0.mamba_fwd.D', 'target_model.mamba_blocks.0.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.A_log', 'target_model.mamba_blocks.0.mamba_bwd.D', 'target_model.mamba_blocks.0.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.0.out_proj.weight', 'target_model.mamba_blocks.0.norm.weight', 'target_model.mamba_blocks.0.norm.bias', 'target_model.mamba_blocks.1.in_proj.weight', 'target_model.mamba_blocks.1.conv1d.weight', 'target_model.mamba_blocks.1.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.A_log', 'target_model.mamba_blocks.1.mamba_fwd.D', 'target_model.mamba_blocks.1.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.A_log', 'target_model.mamba_blocks.1.mamba_bwd.D', 'target_model.mamba_blocks.1.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.1.out_proj.weight', 'target_model.mamba_blocks.1.norm.weight', 'target_model.mamba_blocks.1.norm.bias', 'target_model.mamba_blocks.2.in_proj.weight', 'target_model.mamba_blocks.2.conv1d.weight', 'target_model.mamba_blocks.2.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.A_log', 'target_model.mamba_blocks.2.mamba_fwd.D', 'target_model.mamba_blocks.2.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.A_log', 'target_model.mamba_blocks.2.mamba_bwd.D', 'target_model.mamba_blocks.2.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.2.out_proj.weight', 'target_model.mamba_blocks.2.norm.weight', 'target_model.mamba_blocks.2.norm.bias', 'target_model.mamba_blocks.3.in_proj.weight', 'target_model.mamba_blocks.3.conv1d.weight', 'target_model.mamba_blocks.3.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.A_log', 'target_model.mamba_blocks.3.mamba_fwd.D', 'target_model.mamba_blocks.3.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.A_log', 'target_model.mamba_blocks.3.mamba_bwd.D', 'target_model.mamba_blocks.3.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.3.out_proj.weight', 'target_model.mamba_blocks.3.norm.weight', 'target_model.mamba_blocks.3.norm.bias', 'target_model.mamba_blocks.4.in_proj.weight', 'target_model.mamba_blocks.4.conv1d.weight', 'target_model.mamba_blocks.4.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.A_log', 'target_model.mamba_blocks.4.mamba_fwd.D', 'target_model.mamba_blocks.4.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.A_log', 'target_model.mamba_blocks.4.mamba_bwd.D', 'target_model.mamba_blocks.4.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.4.out_proj.weight', 'target_model.mamba_blocks.4.norm.weight', 'target_model.mamba_blocks.4.norm.bias', 'target_model.mamba_blocks.5.in_proj.weight', 'target_model.mamba_blocks.5.conv1d.weight', 'target_model.mamba_blocks.5.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.A_log', 'target_model.mamba_blocks.5.mamba_fwd.D', 'target_model.mamba_blocks.5.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.A_log', 'target_model.mamba_blocks.5.mamba_bwd.D', 'target_model.mamba_blocks.5.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.5.out_proj.weight', 'target_model.mamba_blocks.5.norm.weight', 'target_model.mamba_blocks.5.norm.bias', 'target_model.mamba_blocks.6.in_proj.weight', 'target_model.mamba_blocks.6.conv1d.weight', 'target_model.mamba_blocks.6.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.A_log', 'target_model.mamba_blocks.6.mamba_fwd.D', 'target_model.mamba_blocks.6.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.A_log', 'target_model.mamba_blocks.6.mamba_bwd.D', 'target_model.mamba_blocks.6.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.6.out_proj.weight', 'target_model.mamba_blocks.6.norm.weight', 'target_model.mamba_blocks.6.norm.bias', 'target_model.mamba_blocks.7.in_proj.weight', 'target_model.mamba_blocks.7.conv1d.weight', 'target_model.mamba_blocks.7.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.A_log', 'target_model.mamba_blocks.7.mamba_fwd.D', 'target_model.mamba_blocks.7.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.A_log', 'target_model.mamba_blocks.7.mamba_bwd.D', 'target_model.mamba_blocks.7.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.7.out_proj.weight', 'target_model.mamba_blocks.7.norm.weight', 'target_model.mamba_blocks.7.norm.bias', 'target_model.norm_f.weight', 'target_model.norm_f.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = \"finetune_weight/pretrain_epoch020.pt\"\n",
    "state_dict = torch.load(weight_path, map_location=DEVICE)\n",
    "model_state = state_dict[\"model_state\"]\n",
    "\n",
    "model.backbone.load_state_dict(model_state, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "107f2f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['cls_token', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'mamba_blocks.0.in_proj.weight', 'mamba_blocks.0.conv1d.weight', 'mamba_blocks.0.conv1d.bias', 'mamba_blocks.0.mamba_fwd.A_log', 'mamba_blocks.0.mamba_fwd.D', 'mamba_blocks.0.mamba_fwd.in_proj.weight', 'mamba_blocks.0.mamba_fwd.conv1d.weight', 'mamba_blocks.0.mamba_fwd.conv1d.bias', 'mamba_blocks.0.mamba_fwd.x_proj.weight', 'mamba_blocks.0.mamba_fwd.dt_proj.weight', 'mamba_blocks.0.mamba_fwd.dt_proj.bias', 'mamba_blocks.0.mamba_fwd.out_proj.weight', 'mamba_blocks.0.mamba_bwd.A_log', 'mamba_blocks.0.mamba_bwd.D', 'mamba_blocks.0.mamba_bwd.in_proj.weight', 'mamba_blocks.0.mamba_bwd.conv1d.weight', 'mamba_blocks.0.mamba_bwd.conv1d.bias', 'mamba_blocks.0.mamba_bwd.x_proj.weight', 'mamba_blocks.0.mamba_bwd.dt_proj.weight', 'mamba_blocks.0.mamba_bwd.dt_proj.bias', 'mamba_blocks.0.mamba_bwd.out_proj.weight', 'mamba_blocks.0.out_proj.weight', 'mamba_blocks.0.norm.weight', 'mamba_blocks.0.norm.bias', 'mamba_blocks.1.in_proj.weight', 'mamba_blocks.1.conv1d.weight', 'mamba_blocks.1.conv1d.bias', 'mamba_blocks.1.mamba_fwd.A_log', 'mamba_blocks.1.mamba_fwd.D', 'mamba_blocks.1.mamba_fwd.in_proj.weight', 'mamba_blocks.1.mamba_fwd.conv1d.weight', 'mamba_blocks.1.mamba_fwd.conv1d.bias', 'mamba_blocks.1.mamba_fwd.x_proj.weight', 'mamba_blocks.1.mamba_fwd.dt_proj.weight', 'mamba_blocks.1.mamba_fwd.dt_proj.bias', 'mamba_blocks.1.mamba_fwd.out_proj.weight', 'mamba_blocks.1.mamba_bwd.A_log', 'mamba_blocks.1.mamba_bwd.D', 'mamba_blocks.1.mamba_bwd.in_proj.weight', 'mamba_blocks.1.mamba_bwd.conv1d.weight', 'mamba_blocks.1.mamba_bwd.conv1d.bias', 'mamba_blocks.1.mamba_bwd.x_proj.weight', 'mamba_blocks.1.mamba_bwd.dt_proj.weight', 'mamba_blocks.1.mamba_bwd.dt_proj.bias', 'mamba_blocks.1.mamba_bwd.out_proj.weight', 'mamba_blocks.1.out_proj.weight', 'mamba_blocks.1.norm.weight', 'mamba_blocks.1.norm.bias', 'mamba_blocks.2.in_proj.weight', 'mamba_blocks.2.conv1d.weight', 'mamba_blocks.2.conv1d.bias', 'mamba_blocks.2.mamba_fwd.A_log', 'mamba_blocks.2.mamba_fwd.D', 'mamba_blocks.2.mamba_fwd.in_proj.weight', 'mamba_blocks.2.mamba_fwd.conv1d.weight', 'mamba_blocks.2.mamba_fwd.conv1d.bias', 'mamba_blocks.2.mamba_fwd.x_proj.weight', 'mamba_blocks.2.mamba_fwd.dt_proj.weight', 'mamba_blocks.2.mamba_fwd.dt_proj.bias', 'mamba_blocks.2.mamba_fwd.out_proj.weight', 'mamba_blocks.2.mamba_bwd.A_log', 'mamba_blocks.2.mamba_bwd.D', 'mamba_blocks.2.mamba_bwd.in_proj.weight', 'mamba_blocks.2.mamba_bwd.conv1d.weight', 'mamba_blocks.2.mamba_bwd.conv1d.bias', 'mamba_blocks.2.mamba_bwd.x_proj.weight', 'mamba_blocks.2.mamba_bwd.dt_proj.weight', 'mamba_blocks.2.mamba_bwd.dt_proj.bias', 'mamba_blocks.2.mamba_bwd.out_proj.weight', 'mamba_blocks.2.out_proj.weight', 'mamba_blocks.2.norm.weight', 'mamba_blocks.2.norm.bias', 'mamba_blocks.3.in_proj.weight', 'mamba_blocks.3.conv1d.weight', 'mamba_blocks.3.conv1d.bias', 'mamba_blocks.3.mamba_fwd.A_log', 'mamba_blocks.3.mamba_fwd.D', 'mamba_blocks.3.mamba_fwd.in_proj.weight', 'mamba_blocks.3.mamba_fwd.conv1d.weight', 'mamba_blocks.3.mamba_fwd.conv1d.bias', 'mamba_blocks.3.mamba_fwd.x_proj.weight', 'mamba_blocks.3.mamba_fwd.dt_proj.weight', 'mamba_blocks.3.mamba_fwd.dt_proj.bias', 'mamba_blocks.3.mamba_fwd.out_proj.weight', 'mamba_blocks.3.mamba_bwd.A_log', 'mamba_blocks.3.mamba_bwd.D', 'mamba_blocks.3.mamba_bwd.in_proj.weight', 'mamba_blocks.3.mamba_bwd.conv1d.weight', 'mamba_blocks.3.mamba_bwd.conv1d.bias', 'mamba_blocks.3.mamba_bwd.x_proj.weight', 'mamba_blocks.3.mamba_bwd.dt_proj.weight', 'mamba_blocks.3.mamba_bwd.dt_proj.bias', 'mamba_blocks.3.mamba_bwd.out_proj.weight', 'mamba_blocks.3.out_proj.weight', 'mamba_blocks.3.norm.weight', 'mamba_blocks.3.norm.bias', 'mamba_blocks.4.in_proj.weight', 'mamba_blocks.4.conv1d.weight', 'mamba_blocks.4.conv1d.bias', 'mamba_blocks.4.mamba_fwd.A_log', 'mamba_blocks.4.mamba_fwd.D', 'mamba_blocks.4.mamba_fwd.in_proj.weight', 'mamba_blocks.4.mamba_fwd.conv1d.weight', 'mamba_blocks.4.mamba_fwd.conv1d.bias', 'mamba_blocks.4.mamba_fwd.x_proj.weight', 'mamba_blocks.4.mamba_fwd.dt_proj.weight', 'mamba_blocks.4.mamba_fwd.dt_proj.bias', 'mamba_blocks.4.mamba_fwd.out_proj.weight', 'mamba_blocks.4.mamba_bwd.A_log', 'mamba_blocks.4.mamba_bwd.D', 'mamba_blocks.4.mamba_bwd.in_proj.weight', 'mamba_blocks.4.mamba_bwd.conv1d.weight', 'mamba_blocks.4.mamba_bwd.conv1d.bias', 'mamba_blocks.4.mamba_bwd.x_proj.weight', 'mamba_blocks.4.mamba_bwd.dt_proj.weight', 'mamba_blocks.4.mamba_bwd.dt_proj.bias', 'mamba_blocks.4.mamba_bwd.out_proj.weight', 'mamba_blocks.4.out_proj.weight', 'mamba_blocks.4.norm.weight', 'mamba_blocks.4.norm.bias', 'mamba_blocks.5.in_proj.weight', 'mamba_blocks.5.conv1d.weight', 'mamba_blocks.5.conv1d.bias', 'mamba_blocks.5.mamba_fwd.A_log', 'mamba_blocks.5.mamba_fwd.D', 'mamba_blocks.5.mamba_fwd.in_proj.weight', 'mamba_blocks.5.mamba_fwd.conv1d.weight', 'mamba_blocks.5.mamba_fwd.conv1d.bias', 'mamba_blocks.5.mamba_fwd.x_proj.weight', 'mamba_blocks.5.mamba_fwd.dt_proj.weight', 'mamba_blocks.5.mamba_fwd.dt_proj.bias', 'mamba_blocks.5.mamba_fwd.out_proj.weight', 'mamba_blocks.5.mamba_bwd.A_log', 'mamba_blocks.5.mamba_bwd.D', 'mamba_blocks.5.mamba_bwd.in_proj.weight', 'mamba_blocks.5.mamba_bwd.conv1d.weight', 'mamba_blocks.5.mamba_bwd.conv1d.bias', 'mamba_blocks.5.mamba_bwd.x_proj.weight', 'mamba_blocks.5.mamba_bwd.dt_proj.weight', 'mamba_blocks.5.mamba_bwd.dt_proj.bias', 'mamba_blocks.5.mamba_bwd.out_proj.weight', 'mamba_blocks.5.out_proj.weight', 'mamba_blocks.5.norm.weight', 'mamba_blocks.5.norm.bias', 'mamba_blocks.6.in_proj.weight', 'mamba_blocks.6.conv1d.weight', 'mamba_blocks.6.conv1d.bias', 'mamba_blocks.6.mamba_fwd.A_log', 'mamba_blocks.6.mamba_fwd.D', 'mamba_blocks.6.mamba_fwd.in_proj.weight', 'mamba_blocks.6.mamba_fwd.conv1d.weight', 'mamba_blocks.6.mamba_fwd.conv1d.bias', 'mamba_blocks.6.mamba_fwd.x_proj.weight', 'mamba_blocks.6.mamba_fwd.dt_proj.weight', 'mamba_blocks.6.mamba_fwd.dt_proj.bias', 'mamba_blocks.6.mamba_fwd.out_proj.weight', 'mamba_blocks.6.mamba_bwd.A_log', 'mamba_blocks.6.mamba_bwd.D', 'mamba_blocks.6.mamba_bwd.in_proj.weight', 'mamba_blocks.6.mamba_bwd.conv1d.weight', 'mamba_blocks.6.mamba_bwd.conv1d.bias', 'mamba_blocks.6.mamba_bwd.x_proj.weight', 'mamba_blocks.6.mamba_bwd.dt_proj.weight', 'mamba_blocks.6.mamba_bwd.dt_proj.bias', 'mamba_blocks.6.mamba_bwd.out_proj.weight', 'mamba_blocks.6.out_proj.weight', 'mamba_blocks.6.norm.weight', 'mamba_blocks.6.norm.bias', 'mamba_blocks.7.in_proj.weight', 'mamba_blocks.7.conv1d.weight', 'mamba_blocks.7.conv1d.bias', 'mamba_blocks.7.mamba_fwd.A_log', 'mamba_blocks.7.mamba_fwd.D', 'mamba_blocks.7.mamba_fwd.in_proj.weight', 'mamba_blocks.7.mamba_fwd.conv1d.weight', 'mamba_blocks.7.mamba_fwd.conv1d.bias', 'mamba_blocks.7.mamba_fwd.x_proj.weight', 'mamba_blocks.7.mamba_fwd.dt_proj.weight', 'mamba_blocks.7.mamba_fwd.dt_proj.bias', 'mamba_blocks.7.mamba_fwd.out_proj.weight', 'mamba_blocks.7.mamba_bwd.A_log', 'mamba_blocks.7.mamba_bwd.D', 'mamba_blocks.7.mamba_bwd.in_proj.weight', 'mamba_blocks.7.mamba_bwd.conv1d.weight', 'mamba_blocks.7.mamba_bwd.conv1d.bias', 'mamba_blocks.7.mamba_bwd.x_proj.weight', 'mamba_blocks.7.mamba_bwd.dt_proj.weight', 'mamba_blocks.7.mamba_bwd.dt_proj.bias', 'mamba_blocks.7.mamba_bwd.out_proj.weight', 'mamba_blocks.7.out_proj.weight', 'mamba_blocks.7.norm.weight', 'mamba_blocks.7.norm.bias', 'norm_f.weight', 'norm_f.bias', 'target_model.cls_token', 'target_model.patch_embed.proj.weight', 'target_model.patch_embed.proj.bias', 'target_model.mamba_blocks.0.in_proj.weight', 'target_model.mamba_blocks.0.conv1d.weight', 'target_model.mamba_blocks.0.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.A_log', 'target_model.mamba_blocks.0.mamba_fwd.D', 'target_model.mamba_blocks.0.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.A_log', 'target_model.mamba_blocks.0.mamba_bwd.D', 'target_model.mamba_blocks.0.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.0.out_proj.weight', 'target_model.mamba_blocks.0.norm.weight', 'target_model.mamba_blocks.0.norm.bias', 'target_model.mamba_blocks.1.in_proj.weight', 'target_model.mamba_blocks.1.conv1d.weight', 'target_model.mamba_blocks.1.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.A_log', 'target_model.mamba_blocks.1.mamba_fwd.D', 'target_model.mamba_blocks.1.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.A_log', 'target_model.mamba_blocks.1.mamba_bwd.D', 'target_model.mamba_blocks.1.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.1.out_proj.weight', 'target_model.mamba_blocks.1.norm.weight', 'target_model.mamba_blocks.1.norm.bias', 'target_model.mamba_blocks.2.in_proj.weight', 'target_model.mamba_blocks.2.conv1d.weight', 'target_model.mamba_blocks.2.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.A_log', 'target_model.mamba_blocks.2.mamba_fwd.D', 'target_model.mamba_blocks.2.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.A_log', 'target_model.mamba_blocks.2.mamba_bwd.D', 'target_model.mamba_blocks.2.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.2.out_proj.weight', 'target_model.mamba_blocks.2.norm.weight', 'target_model.mamba_blocks.2.norm.bias', 'target_model.mamba_blocks.3.in_proj.weight', 'target_model.mamba_blocks.3.conv1d.weight', 'target_model.mamba_blocks.3.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.A_log', 'target_model.mamba_blocks.3.mamba_fwd.D', 'target_model.mamba_blocks.3.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.A_log', 'target_model.mamba_blocks.3.mamba_bwd.D', 'target_model.mamba_blocks.3.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.3.out_proj.weight', 'target_model.mamba_blocks.3.norm.weight', 'target_model.mamba_blocks.3.norm.bias', 'target_model.mamba_blocks.4.in_proj.weight', 'target_model.mamba_blocks.4.conv1d.weight', 'target_model.mamba_blocks.4.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.A_log', 'target_model.mamba_blocks.4.mamba_fwd.D', 'target_model.mamba_blocks.4.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.A_log', 'target_model.mamba_blocks.4.mamba_bwd.D', 'target_model.mamba_blocks.4.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.4.out_proj.weight', 'target_model.mamba_blocks.4.norm.weight', 'target_model.mamba_blocks.4.norm.bias', 'target_model.mamba_blocks.5.in_proj.weight', 'target_model.mamba_blocks.5.conv1d.weight', 'target_model.mamba_blocks.5.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.A_log', 'target_model.mamba_blocks.5.mamba_fwd.D', 'target_model.mamba_blocks.5.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.A_log', 'target_model.mamba_blocks.5.mamba_bwd.D', 'target_model.mamba_blocks.5.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.5.out_proj.weight', 'target_model.mamba_blocks.5.norm.weight', 'target_model.mamba_blocks.5.norm.bias', 'target_model.mamba_blocks.6.in_proj.weight', 'target_model.mamba_blocks.6.conv1d.weight', 'target_model.mamba_blocks.6.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.A_log', 'target_model.mamba_blocks.6.mamba_fwd.D', 'target_model.mamba_blocks.6.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.A_log', 'target_model.mamba_blocks.6.mamba_bwd.D', 'target_model.mamba_blocks.6.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.6.out_proj.weight', 'target_model.mamba_blocks.6.norm.weight', 'target_model.mamba_blocks.6.norm.bias', 'target_model.mamba_blocks.7.in_proj.weight', 'target_model.mamba_blocks.7.conv1d.weight', 'target_model.mamba_blocks.7.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.A_log', 'target_model.mamba_blocks.7.mamba_fwd.D', 'target_model.mamba_blocks.7.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.A_log', 'target_model.mamba_blocks.7.mamba_bwd.D', 'target_model.mamba_blocks.7.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.7.out_proj.weight', 'target_model.mamba_blocks.7.norm.weight', 'target_model.mamba_blocks.7.norm.bias', 'target_model.norm_f.weight', 'target_model.norm_f.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state = state_dict[\"model_state\"]\n",
    "model_state.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ffd9f",
   "metadata": {},
   "source": [
    "### Loading Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9457468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lr_scheduler import CosineLRScheduler\n",
    "\n",
    "try:\n",
    "    from eegdash.dataset import EEGChallengeDataset\n",
    "    from eegdash.hbn.windows import (\n",
    "        annotate_trials_with_target,\n",
    "        add_aux_anchors,\n",
    "        add_extras_columns,\n",
    "        keep_only_recordings_with,\n",
    "    )\n",
    "except Exception as e:\n",
    "    EEGChallengeDataset = None\n",
    "\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_windows_from_events\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "import torch.nn as nn\n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "import joblib\n",
    "from braindecode.datasets.base import EEGWindowsDataset, BaseConcatDataset, BaseDataset\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c337832",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"LOL_DATASET/LOL_DATASET/HBN_DATA_FULL/\"\n",
    "RELEASES = [\"R1\"]\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SFREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2270bbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=281913;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=534545;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_datasets = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    name_folder = f\"{rel}_mini_L100_bdf\" \n",
    "    cache_dir = Path(DATA_PATH) / name_folder \n",
    "\n",
    "    dataset = EEGChallengeDataset(\n",
    "        cache_dir = cache_dir,\n",
    "        task = \"contrastChangeDetection\",\n",
    "        mini = True,\n",
    "        download = False,\n",
    "        release = rel,\n",
    "        description_fields = [\n",
    "            \"subject\",\n",
    "            \"session\",\n",
    "            \"run\",\n",
    "            \"task\",\n",
    "            \"age\",\n",
    "            \"gender\",\n",
    "            \"sex\",\n",
    "            \"p_factor\",\n",
    "            # \"internalizing\",\n",
    "            # \"externalizing\",\n",
    "            # \"ehq_total\",\n",
    "            # \"commercial_use\",\n",
    "            # \"full_pheno\",\n",
    "            # \"attention\"\n",
    "            \n",
    "        ],\n",
    "\n",
    "        \n",
    "    )\n",
    "\n",
    "    all_datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900abc6",
   "metadata": {},
   "source": [
    " ## 2. Wrap the data into a PyTorch-compatible dataset\n",
    "\n",
    " The class below defines a dataset wrapper that will extract 2-second windows,\n",
    " uniformly sampled over the whole signal. In addition, it will add useful information\n",
    " about the extracted windows, such as the externalizing factor, the subject or the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6e845ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWrapper(BaseDataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset: EEGWindowsDataset,\n",
    "        crop_size_samples: int,\n",
    "        target_name: str = \"externalizing\",\n",
    "        seed = None,\n",
    "    ):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.crop_size_samples = crop_size_samples\n",
    "        self.target_name = target_name\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, _, crop_inds = self.dataset[idx]\n",
    "\n",
    "        target = self.dataset.description[self.target_name]\n",
    "        print(target)\n",
    "        target = float(target)\n",
    "\n",
    "        # Additional information\n",
    "        infos = {\n",
    "            \"subject\": self.dataset.description[\"subject\"],\n",
    "            \"sex\": self.dataset.description[\"sex\"],\n",
    "            \"age\": float(self.dataset.description[\"age\"]),\n",
    "            \"task\": self.dataset.description[\"task\"],\n",
    "            \"session\": self.dataset.description.get(\"session\", None) or \"\",\n",
    "            \"run\": self.dataset.description.get(\"run\", None) or \"\",\n",
    "        }\n",
    "\n",
    "        # Random cropping the EEG waves to the size of crop_size_samples \n",
    "        i_window_in_trial, i_start, i_stop = crop_inds\n",
    "        assert i_stop - i_start >= self.crop_size_samples, f\"{i_stop=} {i_start=}\"\n",
    "        start_offset = self.rng.integers(0, i_stop - i_start - self.crop_size_samples + 1)\n",
    "        i_start = i_start + start_offset \n",
    "        i_stop  = i_start + self.crop_size_samples\n",
    "\n",
    "        return X, target, (i_window_in_trial, i_start, i_stop), infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56e3b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "import math\n",
    "\n",
    "preproc_dir = Path(\"preprocessed_dataset\")\n",
    "preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "list_windows = []\n",
    "\n",
    "for idx, data in enumerate(all_datasets):\n",
    "    filter_data = BaseConcatDataset(\n",
    "       [\n",
    "            ds \n",
    "            for ds in data.datasets\n",
    "            if ds.raw.n_times >= 4 * SFREQ\n",
    "            and len(ds.raw.ch_names) == 129\n",
    "            and not math.isnan(ds.description[\"p_factor\"])\n",
    "       ] \n",
    "    )\n",
    "\n",
    "    # Create 4-seconds windows with 2-seconds stride\n",
    "    windows_ds = create_fixed_length_windows(\n",
    "        filter_data,\n",
    "        window_size_samples=4 * SFREQ,\n",
    "        window_stride_samples=2 * SFREQ,\n",
    "        drop_last_window=True,\n",
    "    )\n",
    "    windows_ds = BaseConcatDataset(\n",
    "            [DatasetWrapper(ds, crop_size_samples=2 * SFREQ) for ds in windows_ds.datasets]\n",
    "    )\n",
    "\n",
    "    list_windows.append(windows_ds)\n",
    "\n",
    "    save_path = preproc_dir / f\"{RELEASES[idx]}_windows.pkl\"\n",
    "    joblib.dump(windows_ds, save_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3b3fd357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 6.4831329e-05, -6.1362621e-06,  1.8794045e-08, ...,\n",
       "         -5.5702254e-05, -5.8715075e-05, -5.6652494e-05],\n",
       "        [ 2.9976351e-05, -3.7022841e-05, -2.9796010e-05, ...,\n",
       "         -9.4364950e-05, -1.0916590e-04, -1.0272729e-04],\n",
       "        [ 1.0300881e-05, -4.5629182e-05, -3.3451066e-05, ...,\n",
       "          3.5722020e-05,  3.0152774e-05,  3.3893011e-05],\n",
       "        ...,\n",
       "        [ 8.1039987e-05,  5.8947244e-05,  6.8126959e-05, ...,\n",
       "         -1.8899624e-05, -7.7549084e-06, -9.7040192e-06],\n",
       "        [ 7.7256365e-05,  1.5659152e-05,  2.8310096e-05, ...,\n",
       "         -2.1114942e-05, -1.2811515e-05, -1.4344756e-05],\n",
       "        [ 5.0000005e-13,  5.0000005e-13,  5.0000005e-13, ...,\n",
       "          5.0000005e-13,  5.0000005e-13,  5.0000005e-13]],\n",
       "       shape=(129, 400), dtype=float32),\n",
       " 0.62,\n",
       " (0, np.int64(80), np.int64(280)),\n",
       " {'subject': 'NDARAB793GL3',\n",
       "  'sex': 'M',\n",
       "  'age': 13.4391,\n",
       "  'task': 'contrastChangeDetection',\n",
       "  'session': '',\n",
       "  'run': '1'})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded1401",
   "metadata": {},
   "source": [
    "#### Testing the whole procedure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a0d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import joblib, math, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from braindecode.datasets.base import EEGWindowsDataset, BaseConcatDataset, BaseDataset\n",
    "from eegdash.dataset import EEGChallengeDataset\n",
    "from tqdm.notebook import tqdm\n",
    "import typing\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49aa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "SFREQ = 100\n",
    "CROP_SEC = 2\n",
    "WINDOW_SEC = 4\n",
    "STRIDE_SEC = 2\n",
    "\n",
    "DATA_PATH = Path(\"MyEEGData_mini/\")\n",
    "RELEASES = [\"R1\"]\n",
    "\n",
    "TASK_NAMES = [\n",
    "    \"RestingState\", \"DespicableMe\", \"DiaryOfAWimpyKid\", \"FunwithFractals\",\n",
    "    \"ThePresent\", \"contrastChangeDetection\", \"seqLearning6target\",\n",
    "    \"seqLearning8target\", \"surroundSupp\", \"symbolSearch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200936ef",
   "metadata": {},
   "source": [
    " 2. Meta Encoder (task + sex + age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b43e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaEncoder:\n",
    "    def __init__(self):\n",
    "        self.task_enc = LabelEncoder()\n",
    "        self.sex_enc = LabelEncoder()\n",
    "        self.age_scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, metas: typing.List[dict]):\n",
    "        tasks = [m[\"task\"] for m in metas]\n",
    "        sexes = [m[\"sex\"] for m in metas]\n",
    "        ages = [[m[\"age\"]] for m in metas]\n",
    "        self.task_enc.fit(tasks)\n",
    "        self.sex_enc.fit(sexes)\n",
    "        self.age_scaler.fit(ages)\n",
    "        self.dim = len(self.task_enc.classes_) + len(self.sex_enc.classes_) + 1\n",
    "        return self\n",
    "\n",
    "    def transform(self, meta: dict) -> torch.Tensor:\n",
    "        t = self.task_enc.transform([meta[\"task\"]])[0]\n",
    "        s = self.sex_enc.transform([meta[\"sex\"]])[0]\n",
    "        a = self.age_scaler.transform([[meta[\"age\"]]])[0, 0]\n",
    "        vec = torch.zeros(self.dim, dtype=torch.float32)\n",
    "        vec[t] = 1.0\n",
    "        vec[len(self.task_enc.classes_) + s] = 1.0\n",
    "        vec[-1] = a\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ab1cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=168367;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=935453;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=67243;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=623640;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=216010;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=938435;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=327908;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=128754;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=228453;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=631128;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=859285;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=632433;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=422504;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=444956;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=482140;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=392807;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=685640;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=476818;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=616178;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=475888;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = []\n",
    "meta_for_encoder = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    folder = f\"{rel}_mini_L100_bdf\"\n",
    "    cache_dir = DATA_PATH / folder\n",
    "    \n",
    "    for task in TASK_NAMES:\n",
    "        ds = EEGChallengeDataset(\n",
    "            cache_dir=cache_dir,\n",
    "            task=task,\n",
    "            mini=True,\n",
    "            download=False,\n",
    "            release=rel,\n",
    "            description_fields=[\n",
    "                \"subject\",\n",
    "                \"session\",\n",
    "                \"run\",\n",
    "                \"task\",\n",
    "                \"age\",\n",
    "                \"gender\",\n",
    "                \"sex\",\n",
    "                \"p_factor\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "        raw_datasets.append(ds)\n",
    "        for sub_ds in ds.datasets:\n",
    "            d = sub_ds.description\n",
    "            if not math.isnan(d.get(\"externalizing\", math.nan)):\n",
    "                meta_for_encoder.append({\n",
    "                    \"task\": d[\"task\"],\n",
    "                    \"sex\": d[\"sex\"],\n",
    "                    \"age\": float(d[\"age\"]),\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f59bbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'RestingState', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'RestingState', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'RestingState', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'RestingState', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'RestingState', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'RestingState', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'RestingState', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'RestingState', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'RestingState', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'DespicableMe', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'DespicableMe', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'DiaryOfAWimpyKid', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'FunwithFractals', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'FunwithFractals', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'ThePresent', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'ThePresent', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'contrastChangeDetection', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'seqLearning6target', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'seqLearning6target', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'seqLearning6target', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'seqLearning6target', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'seqLearning6target', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'seqLearning6target', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'seqLearning6target', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'seqLearning6target', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'seqLearning8target', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'seqLearning8target', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'seqLearning8target', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'seqLearning8target', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'seqLearning8target', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'seqLearning8target', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'seqLearning8target', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'seqLearning8target', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'seqLearning8target', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'seqLearning8target', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'seqLearning8target', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'surroundSupp', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'surroundSupp', 'sex': 'M', 'age': 12.4397},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 11.3386},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 10.9449},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 12.8422},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 13.9757},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 8.6883},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 8.3652},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 6.7472},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 6.6821},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 12.4585},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 9.6883},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 8.453},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 9.3646},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 13.0092},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 10.2002},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 9.926},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 11.8507},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 7.0291},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 10.5204},\n",
       " {'task': 'symbolSearch', 'sex': 'F', 'age': 6.7034},\n",
       " {'task': 'symbolSearch', 'sex': 'M', 'age': 12.4397}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_for_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f492e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta embedding dim: 13\n"
     ]
    }
   ],
   "source": [
    "# Fit global encoder\n",
    "meta_encoder = MetaEncoder().fit(meta_for_encoder)\n",
    "META_DIM = meta_encoder.dim\n",
    "print(f\"Meta embedding dim: {META_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b64516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropMetaWrapper(BaseDataset):\n",
    "    def __init__(self, windows_ds, \n",
    "                        crop_samples, \n",
    "                        meta_encoder, \n",
    "                        target_name=\"externalizing\"):\n",
    "        \n",
    "        self.windows_ds = windows_ds\n",
    "        self.crop_samples = crop_samples\n",
    "        self.meta_encoder = meta_encoder\n",
    "        self.target_name = target_name\n",
    "        self.rng = np.random.default_rng(2025)  # fixed seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows_ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, _, crop_inds = self.windows_ds[idx]  # X: (C, 4*SFREQ)\n",
    "\n",
    "        # Target\n",
    "        target = float(self.windows_ds.description[self.target_name])\n",
    "\n",
    "        # Meta\n",
    "        desc = self.windows_ds.description\n",
    "        meta_dict = {\n",
    "            \"task\": desc[\"task\"],\n",
    "            \"sex\": desc[\"sex\"],\n",
    "            \"age\": float(desc[\"age\"]),\n",
    "        }\n",
    "        meta_vec = self.meta_encoder.transform(meta_dict)\n",
    "\n",
    "        # Random 2s crop\n",
    "        i_win, i_start, i_stop = crop_inds\n",
    "\n",
    "\n",
    "        assert i_stop - i_start >= self.crop_samples\n",
    "\n",
    "        # FIXED: .integers instead of .randint\n",
    "        offset = self.rng.integers(0, i_stop - i_start - self.crop_samples + 1)\n",
    "        i_start = i_start + offset\n",
    "        i_stop = i_start + self.crop_samples\n",
    "        X_crop = X[:, offset : offset + self.crop_samples]  # (C, 2*SFREQ)\n",
    "\n",
    "        # Infos\n",
    "        infos = {\n",
    "            \"subject\": desc[\"subject\"],\n",
    "            \"session\": desc.get(\"session\", \"\"),\n",
    "            \"run\": desc.get(\"run\", \"\"),\n",
    "            \"task\": desc[\"task\"],\n",
    "            \"sex\": desc[\"sex\"],\n",
    "            \"age\": float(desc[\"age\"]),\n",
    "        }\n",
    "\n",
    "        return torch.tensor(X_crop), meta_vec, target, (i_win, i_start, i_stop), infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f06eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[0].release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe788e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RestingState'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[0].description['task'].unique().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8019d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 20\n",
      "R1 20\n",
      "R1 20\n",
      "R1 20\n",
      "R1 20\n",
      "R1 60\n",
      "R1 8\n",
      "R1 11\n",
      "R1 40\n",
      "R1 20\n"
     ]
    }
   ],
   "source": [
    "preproc_dir = Path(\"preprocessed_dataset\")\n",
    "preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "list_windows = []\n",
    "\n",
    "for dataset in raw_datasets:\n",
    "    print(dataset.release, len(dataset.datasets))\n",
    "\n",
    "    rel_raw = [ds for ds in raw_datasets if ds.release == dataset.release]\n",
    "\n",
    "    filtered = BaseConcatDataset([\n",
    "        sub_ds for ds in rel_raw for sub_ds in ds.datasets\n",
    "        if (sub_ds.raw.n_times >= 4 * SFREQ\n",
    "            and len(sub_ds.raw.ch_names) == 129\n",
    "            and not math.isnan(sub_ds.description.get(\"externalizing\", math.nan)))\n",
    "    ])\n",
    "    windows = create_fixed_length_windows(\n",
    "        filtered,\n",
    "        window_size_samples= 4 * SFREQ,\n",
    "        window_stride_samples= 2 * SFREQ,\n",
    "        drop_last_window=True,\n",
    "    )\n",
    "    windows_ds = BaseConcatDataset(\n",
    "        [CropMetaWrapper(\n",
    "            ds, crop_samples=CROP_SEC * SFREQ, meta_encoder=meta_encoder\n",
    "        ) for ds in windows.datasets\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    list_windows.append(windows_ds)\n",
    "    joblib.dump(windows_ds, preproc_dir / f\"{dataset.release}_windows_task[{dataset.description['task'].unique().item()}].pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8b98b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfe2e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363360\n"
     ]
    }
   ],
   "source": [
    "wrapped_windows = BaseConcatDataset(list_windows)\n",
    "print(len(wrapped_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23abf032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363360\n"
     ]
    }
   ],
   "source": [
    "## Loading via windows\n",
    "list_windows = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    for task in TASK_NAMES:\n",
    "        load_path = preproc_dir / f\"{rel}_windows_task[{task}].pkl\"\n",
    "        if load_path.exists():\n",
    "            windows = joblib.load(load_path)\n",
    "            list_windows.append(windows)\n",
    "\n",
    "wrapped_windows = BaseConcatDataset(list_windows)\n",
    "print(len(wrapped_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00bb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RANDOM SPLIT BY LENGTH ===\n",
    "total_len = len(wrapped_windows)\n",
    "train_len = int(0.8 * total_len)\n",
    "valid_len = int(0.1 * total_len)\n",
    "test_len  = total_len - train_len - valid_len\n",
    "\n",
    "train_ds, valid_ds, test_ds = random_split(\n",
    "    wrapped_windows,\n",
    "    [train_len, valid_len, test_len],\n",
    "    generator=torch.Generator().manual_seed(2025)  # reproducible\n",
    ")\n",
    "\n",
    "# === DATALOADERS ===\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X, meta, y, wins, infos = zip(*batch)\n",
    "\n",
    "    return (\n",
    "        torch.stack(X),\n",
    "        torch.stack(meta),\n",
    "        torch.tensor(y, dtype=torch.float32).unsqueeze(1),\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1f90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 129, 200]) torch.Size([16, 13]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch[0].shape, batch[1].shape, batch[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500f9b1",
   "metadata": {},
   "source": [
    "1. MDN Head & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b75942ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_loss(pi, sigma, mu, y, reduce=True):\n",
    "    \"\"\"Calculates the Mixture Density Network loss.\"\"\"\n",
    "    # Ensure y has the correct shape for broadcasting: (B, 1)\n",
    "    if y.dim() == 1: y = y.unsqueeze(-1)\n",
    "    if y.dim() == 2 and y.shape[1] != 1:\n",
    "        raise ValueError(f\"Target y must be shape (B,) or (B, 1), but got {y.shape}\")\n",
    "\n",
    "    # Create the mixture distribution\n",
    "    # Normal distribution component: N(mu | sigma^2)\n",
    "    m = torch.distributions.Normal(loc=mu, scale=sigma)\n",
    "\n",
    "    # Calculate the log probability density for each component\n",
    "    # log N(y | mu_k, sigma_k^2)\n",
    "    # y broadcasts from (B, 1) to (B, N_COMPONENTS)\n",
    "    log_prob = m.log_prob(y)\n",
    "\n",
    "    # Ensure log_prob is numerically stable (clamp potential -inf)\n",
    "    log_prob = torch.clamp(log_prob, min=-1e9, max=1e9) # Also clamp max for stability\n",
    "\n",
    "    # Calculate log mixture weights (log pi_k) using log_softmax for stability\n",
    "    log_pi = torch.log_softmax(pi, dim=1)\n",
    "\n",
    "    # Combine using log-sum-exp for stability: log( sum[ pi_k * N(y | ...) ] )\n",
    "    # logsumexp( log(pi_k) + log N(y | ...) )\n",
    "    log_likelihood = torch.logsumexp(log_pi + log_prob, dim=1)\n",
    "\n",
    "    # Negative log likelihood loss\n",
    "    loss = -log_likelihood\n",
    "\n",
    "    if reduce:\n",
    "        return loss.mean()\n",
    "    else:\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94975dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "from model.mdn import MDNHead\n",
    "\n",
    "\n",
    "class FinetuneJEPA_Challenge2(nn.Module):\n",
    "    def __init__(self, n_channels=129, d_model=256, n_layer=8, patch_size=10, meta_dim=13):\n",
    "        super().__init__()\n",
    "        self.backbone = EegMambaJEPA(\n",
    "            n_channels=n_channels,\n",
    "            d_model=d_model,\n",
    "            n_layer=n_layer,\n",
    "            patch_size=patch_size,\n",
    "        )\n",
    "        self.meta_proj = nn.Linear(meta_dim, d_model)\n",
    "\n",
    "        # MDN Heads\n",
    "        self.train_head = MDNHead(input_dim=d_model * 2, n_mixtures=3)\n",
    "        self.submit_head = MDNHead(input_dim=d_model, n_mixtures=3)\n",
    "\n",
    "        # MODE\n",
    "        self.mode = \"train\"  # \"train\", \"val\", \"submit\"\n",
    "\n",
    "    def forward(self, x, meta=None):\n",
    "        z = self.backbone(x)  # (B, d_model)\n",
    "\n",
    "        if self.mode == \"train\" and meta is not None:\n",
    "            m = self.meta_proj(meta)\n",
    "            z = torch.cat([z, m], dim=-1)\n",
    "            pi, sigma, mu = self.train_head(z)\n",
    "        else:\n",
    "            pi, sigma, mu = self.submit_head(z)\n",
    "\n",
    "        # RETURN BASED ON MODE\n",
    "        if self.mode == \"train\":\n",
    "            return pi, sigma, mu\n",
    "        else:\n",
    "            # EVALUATION / SUBMISSION: Return single number\n",
    "            # Option 1: Mean of mixture (weighted)\n",
    "            pred = (pi * mu).sum(dim=1)  # (B,)\n",
    "            # Option 2: Best component (highest pi)\n",
    "            # best_k = pi.argmax(dim=1)\n",
    "            # pred = mu.gather(1, best_k.unsqueeze(1)).squeeze(1)\n",
    "            return pred\n",
    "\n",
    "    # SWITCH MODES\n",
    "    def train_mode(self):\n",
    "        self.mode = \"train\"\n",
    "        self.train()\n",
    "\n",
    "    def eval_mode(self):\n",
    "        self.mode = \"val\"\n",
    "        self.eval()\n",
    "\n",
    "    def submit_mode(self):\n",
    "        self.mode = \"submit\"\n",
    "        self.eval()\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        print(\"BACKBONE FROZEN. SUBMISSION READY.\")\n",
    "\n",
    "    # FREEZE BACKBONE\n",
    "    def freeze_backbone(self):\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f6be6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinetuneJEPA_Challenge2(\n",
    "    n_channels=129,\n",
    "    d_model=256,\n",
    "    n_layer=8,\n",
    "    patch_size=10,\n",
    "    meta_dim=META_DIM\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d851d680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "x, meta, y = batch\n",
    "x = x.to(DEVICE)\n",
    "y = y.to(DEVICE)\n",
    "meta = meta.to(DEVICE)\n",
    "\n",
    "out = model(x, meta)\n",
    "\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "631f4fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3364, device='cuda:1', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi, sigma, mu = out\n",
    "\n",
    "mdn_loss(pi, sigma, mu, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21cf7e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "model.eval_mode()\n",
    "out = model(x, meta)\n",
    "print(out.shape)  # (B,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a058124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
