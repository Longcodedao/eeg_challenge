{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61b7d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lr_scheduler import CosineLRScheduler\n",
    "\n",
    "try:\n",
    "    from eegdash.dataset import EEGChallengeDataset\n",
    "    from eegdash.hbn.windows import (\n",
    "        annotate_trials_with_target,\n",
    "        add_aux_anchors,\n",
    "        add_extras_columns,\n",
    "        keep_only_recordings_with,\n",
    "    )\n",
    "except Exception as e:\n",
    "    EEGChallengeDataset = None\n",
    "\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_windows_from_events\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "import torch.nn as nn\n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5280edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"LOL_DATASET/LOL_DATASET/HBN_DATA_FULL/\"\n",
    "RELEASES = [\"R1\", \"R2\", \"R3\"]\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b0b68ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=214725;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=411936;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=169652;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=917794;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=798069;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=439694;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dataset = []\n",
    "for rel in RELEASES:\n",
    "    name_folder = f\"{rel}_mini_L100_bdf\" \n",
    "    cache_dir = Path(DATA_PATH) / name_folder \n",
    "\n",
    "    dataset = EEGChallengeDataset(\n",
    "        cache_dir = cache_dir,\n",
    "        task = \"contrastChangeDetection\",\n",
    "        mini = True,\n",
    "        download = False,\n",
    "        release = rel\n",
    "    )\n",
    "\n",
    "    all_dataset.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82683afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7522500"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset = BaseConcatDataset(all_dataset)\n",
    "len(all_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf160ee3",
   "metadata": {},
   "source": [
    "Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c799b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_LENS_S = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8eedbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_offline_preprocessors():\n",
    "    return [\n",
    "        Preprocessor(annotate_trials_with_target, \n",
    "                     target_field = \"rt_from_stimulus\", \n",
    "                     epoch_length = EPOCH_LENS_S, \n",
    "                     require_stimulus = True, \n",
    "                     require_response = True, \n",
    "                     apply_on_array = False),\n",
    "        Preprocessor(add_aux_anchors, apply_on_array=False),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c1264",
   "metadata": {},
   "source": [
    "This case we don't need to save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01da0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n"
     ]
    }
   ],
   "source": [
    "preproc_dir = Path(\"preprocessed_dataset\")\n",
    "preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "list_windows = []\n",
    "\n",
    "ANCHOR = \"stimulus_anchor\"\n",
    "SHIFT_AFTER_STIM = 0.5\n",
    "WINDOW_LEN = 2.0\n",
    "SFREQ = 100\n",
    "\n",
    "preproc = build_offline_preprocessors()\n",
    "\n",
    "for i, dataset in enumerate(all_dataset):\n",
    "    preprocess(dataset, preproc, n_jobs = -1)\n",
    "\n",
    "    dataset = keep_only_recordings_with(ANCHOR, dataset)\n",
    "    windows = create_windows_from_events(\n",
    "        dataset, \n",
    "        mapping = {ANCHOR: 0},\n",
    "        trial_start_offset_samples = int(SHIFT_AFTER_STIM * SFREQ),                 # +0.5 s\n",
    "        trial_stop_offset_samples = int((SHIFT_AFTER_STIM + WINDOW_LEN) * SFREQ),   # +2.5 s\n",
    "        window_size_samples = int(WINDOW_LEN * SFREQ),\n",
    "        window_stride_samples = SFREQ,\n",
    "        preload=True,\n",
    "    )\n",
    "\n",
    "    windows = add_extras_columns(\n",
    "        windows,\n",
    "        dataset,\n",
    "        desc=ANCHOR,\n",
    "        keys=(\"target\", \"rt_from_stimulus\", \"rt_from_trialstart\",\n",
    "              \"stimulus_onset\", \"response_onset\", \"correct\", \"response_type\")\n",
    "    )\n",
    "\n",
    "    list_windows.append(windows)\n",
    "\n",
    "    save_path = preproc_dir / f\"{RELEASES[i]}_windows.pkl\"\n",
    "    joblib.dump(windows, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a02c1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_windows = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    load_path = preproc_dir / f\"{rel}_windows.pkl\"\n",
    "    windows = joblib.load(load_path)\n",
    "    load_windows.append(windows)\n",
    "\n",
    "all_windows = BaseConcatDataset(load_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a626c43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_window_in_trial</th>\n",
       "      <th>i_start_in_trial</th>\n",
       "      <th>i_stop_in_trial</th>\n",
       "      <th>target</th>\n",
       "      <th>rt_from_stimulus</th>\n",
       "      <th>rt_from_trialstart</th>\n",
       "      <th>stimulus_onset</th>\n",
       "      <th>response_onset</th>\n",
       "      <th>correct</th>\n",
       "      <th>response_type</th>\n",
       "      <th>...</th>\n",
       "      <th>thepresent</th>\n",
       "      <th>diaryofawimpykid</th>\n",
       "      <th>contrastchangedetection_1</th>\n",
       "      <th>contrastchangedetection_2</th>\n",
       "      <th>contrastchangedetection_3</th>\n",
       "      <th>surroundsupp_1</th>\n",
       "      <th>surroundsupp_2</th>\n",
       "      <th>seqlearning6target</th>\n",
       "      <th>seqlearning8target</th>\n",
       "      <th>symbolsearch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4278</td>\n",
       "      <td>4478</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>4.93</td>\n",
       "      <td>42.284</td>\n",
       "      <td>44.414</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4798</td>\n",
       "      <td>4998</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.96</td>\n",
       "      <td>4.76</td>\n",
       "      <td>47.484</td>\n",
       "      <td>49.444</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5478</td>\n",
       "      <td>5678</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.42</td>\n",
       "      <td>54.284</td>\n",
       "      <td>56.304</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6318</td>\n",
       "      <td>6518</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>7.72</td>\n",
       "      <td>62.684</td>\n",
       "      <td>64.404</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6838</td>\n",
       "      <td>7038</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>67.884</td>\n",
       "      <td>69.684</td>\n",
       "      <td>1</td>\n",
       "      <td>left_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_window_in_trial  i_start_in_trial  i_stop_in_trial  target  \\\n",
       "0                  0              4278             4478    2.13   \n",
       "1                  0              4798             4998    1.96   \n",
       "2                  0              5478             5678    2.02   \n",
       "3                  0              6318             6518    1.72   \n",
       "4                  0              6838             7038     1.8   \n",
       "\n",
       "   rt_from_stimulus  rt_from_trialstart  stimulus_onset  response_onset  \\\n",
       "0              2.13                4.93          42.284          44.414   \n",
       "1              1.96                4.76          47.484          49.444   \n",
       "2              2.02                6.42          54.284          56.304   \n",
       "3              1.72                7.72          62.684          64.404   \n",
       "4               1.8                 4.6          67.884          69.684   \n",
       "\n",
       "   correct      response_type  ... thepresent diaryofawimpykid  \\\n",
       "0        1  right_buttonPress  ...  available        available   \n",
       "1        1  right_buttonPress  ...  available        available   \n",
       "2        1  right_buttonPress  ...  available        available   \n",
       "3        1  right_buttonPress  ...  available        available   \n",
       "4        1   left_buttonPress  ...  available        available   \n",
       "\n",
       "  contrastchangedetection_1  contrastchangedetection_2  \\\n",
       "0                 available                  available   \n",
       "1                 available                  available   \n",
       "2                 available                  available   \n",
       "3                 available                  available   \n",
       "4                 available                  available   \n",
       "\n",
       "  contrastchangedetection_3 surroundsupp_1  surroundsupp_2 seqlearning6target  \\\n",
       "0                 available      available       available        unavailable   \n",
       "1                 available      available       available        unavailable   \n",
       "2                 available      available       available        unavailable   \n",
       "3                 available      available       available        unavailable   \n",
       "4                 available      available       available        unavailable   \n",
       "\n",
       "  seqlearning8target  symbolsearch  \n",
       "0          available     available  \n",
       "1          available     available  \n",
       "2          available     available  \n",
       "3          available     available  \n",
       "4          available     available  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_windows.get_metadata().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d44240",
   "metadata": {},
   "source": [
    "#### Spliting the train test valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5b6d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = all_windows.get_metadata()\n",
    "subjects = list(meta['subject'].unique())\n",
    "\n",
    "valid_frac = 0.1\n",
    "test_frac = 0.1\n",
    "seed = 2025\n",
    "\n",
    "train_subj, valid_test_subject = train_test_split(subjects, test_size=(valid_frac + test_frac), random_state=check_random_state(seed), shuffle=True)\n",
    "valid_subj, test_subj = train_test_split(valid_test_subject, test_size=test_frac/(valid_frac+test_frac), random_state=check_random_state(seed+1), shuffle=True)\n",
    "\n",
    "subject_split = windows.split(\"subject\")\n",
    "train_sets = [ds for subj, ds in subject_split.items() if subj in train_subj]\n",
    "valid_sets = [ds for subj, ds in subject_split.items() if subj in valid_subj]\n",
    "test_sets = [ds for subj, ds in subject_split.items() if subj in test_subj]\n",
    "\n",
    "train_ds = BaseConcatDataset(train_sets)\n",
    "valid_ds = BaseConcatDataset(valid_sets)\n",
    "test_ds = BaseConcatDataset(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ddada97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "134\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(valid_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c8d00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastChangeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, braindecode_dataset):\n",
    "        self.dataset = braindecode_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y, _ = self.dataset[idx]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "train_dataset = ContrastChangeDataset(train_ds)\n",
    "valid_dataset = ContrastChangeDataset(valid_ds)\n",
    "test_dataset = ContrastChangeDataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49f66893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2222e-05,  5.1986e-06,  5.3049e-06,  ..., -8.8720e-07,\n",
       "           7.3418e-07, -9.9474e-07],\n",
       "         [ 1.1537e-05,  5.4671e-06,  5.5437e-06,  ..., -6.2149e-07,\n",
       "           1.2688e-06,  3.0214e-07],\n",
       "         [ 1.3410e-05,  6.8182e-06,  5.9050e-06,  ...,  8.5317e-07,\n",
       "           1.7593e-06,  8.2808e-07],\n",
       "         ...,\n",
       "         [-8.4166e-06, -1.0888e-05, -9.3056e-06,  ...,  6.8735e-06,\n",
       "           3.1253e-06,  1.5513e-06],\n",
       "         [-1.2049e-05, -1.4262e-05, -1.3558e-05,  ...,  9.3226e-06,\n",
       "           5.4775e-06,  2.9852e-06],\n",
       "         [ 5.0000e-13,  5.0000e-13,  5.0000e-13,  ...,  5.0000e-13,\n",
       "           5.0000e-13,  5.0000e-13]]),\n",
       " tensor([1.9580]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = train_dataset[0]\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4315bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f622c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 129, 200]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "first_batch[0].shape, first_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28971512",
   "metadata": {},
   "source": [
    "Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd4945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/eeg_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "\n",
    "class FinetuneJEPA(nn.Module):\n",
    "    \"\"\"Simple wrapper: EegMambaJEPA backbone -> linear regression head.\"\"\"\n",
    "    def __init__(self, \n",
    "                 n_chans: int = 129, \n",
    "                 d_model: int = 256, \n",
    "                 n_layer: int = 8, \n",
    "                 patch_size: int = 10\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.backbone = EegMambaJEPA(\n",
    "            d_model=d_model, \n",
    "            n_layer=n_layer, \n",
    "            n_channels=n_chans, \n",
    "            patch_size=patch_size\n",
    "            )\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, C, T)\n",
    "        z = self.backbone(x)  # (B, d_model)\n",
    "        out = self.head(z)    # (B, 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2605e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = FinetuneJEPA(n_chans=129, d_model=256, n_layer=8, patch_size=10)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31e1ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['target_model.cls_token', 'target_model.patch_embed.proj.weight', 'target_model.patch_embed.proj.bias', 'target_model.mamba_blocks.0.in_proj.weight', 'target_model.mamba_blocks.0.conv1d.weight', 'target_model.mamba_blocks.0.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.A_log', 'target_model.mamba_blocks.0.mamba_fwd.D', 'target_model.mamba_blocks.0.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.A_log', 'target_model.mamba_blocks.0.mamba_bwd.D', 'target_model.mamba_blocks.0.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.0.out_proj.weight', 'target_model.mamba_blocks.0.norm.weight', 'target_model.mamba_blocks.0.norm.bias', 'target_model.mamba_blocks.1.in_proj.weight', 'target_model.mamba_blocks.1.conv1d.weight', 'target_model.mamba_blocks.1.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.A_log', 'target_model.mamba_blocks.1.mamba_fwd.D', 'target_model.mamba_blocks.1.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.A_log', 'target_model.mamba_blocks.1.mamba_bwd.D', 'target_model.mamba_blocks.1.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.1.out_proj.weight', 'target_model.mamba_blocks.1.norm.weight', 'target_model.mamba_blocks.1.norm.bias', 'target_model.mamba_blocks.2.in_proj.weight', 'target_model.mamba_blocks.2.conv1d.weight', 'target_model.mamba_blocks.2.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.A_log', 'target_model.mamba_blocks.2.mamba_fwd.D', 'target_model.mamba_blocks.2.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.A_log', 'target_model.mamba_blocks.2.mamba_bwd.D', 'target_model.mamba_blocks.2.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.2.out_proj.weight', 'target_model.mamba_blocks.2.norm.weight', 'target_model.mamba_blocks.2.norm.bias', 'target_model.mamba_blocks.3.in_proj.weight', 'target_model.mamba_blocks.3.conv1d.weight', 'target_model.mamba_blocks.3.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.A_log', 'target_model.mamba_blocks.3.mamba_fwd.D', 'target_model.mamba_blocks.3.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.A_log', 'target_model.mamba_blocks.3.mamba_bwd.D', 'target_model.mamba_blocks.3.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.3.out_proj.weight', 'target_model.mamba_blocks.3.norm.weight', 'target_model.mamba_blocks.3.norm.bias', 'target_model.mamba_blocks.4.in_proj.weight', 'target_model.mamba_blocks.4.conv1d.weight', 'target_model.mamba_blocks.4.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.A_log', 'target_model.mamba_blocks.4.mamba_fwd.D', 'target_model.mamba_blocks.4.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.A_log', 'target_model.mamba_blocks.4.mamba_bwd.D', 'target_model.mamba_blocks.4.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.4.out_proj.weight', 'target_model.mamba_blocks.4.norm.weight', 'target_model.mamba_blocks.4.norm.bias', 'target_model.mamba_blocks.5.in_proj.weight', 'target_model.mamba_blocks.5.conv1d.weight', 'target_model.mamba_blocks.5.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.A_log', 'target_model.mamba_blocks.5.mamba_fwd.D', 'target_model.mamba_blocks.5.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.A_log', 'target_model.mamba_blocks.5.mamba_bwd.D', 'target_model.mamba_blocks.5.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.5.out_proj.weight', 'target_model.mamba_blocks.5.norm.weight', 'target_model.mamba_blocks.5.norm.bias', 'target_model.mamba_blocks.6.in_proj.weight', 'target_model.mamba_blocks.6.conv1d.weight', 'target_model.mamba_blocks.6.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.A_log', 'target_model.mamba_blocks.6.mamba_fwd.D', 'target_model.mamba_blocks.6.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.A_log', 'target_model.mamba_blocks.6.mamba_bwd.D', 'target_model.mamba_blocks.6.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.6.out_proj.weight', 'target_model.mamba_blocks.6.norm.weight', 'target_model.mamba_blocks.6.norm.bias', 'target_model.mamba_blocks.7.in_proj.weight', 'target_model.mamba_blocks.7.conv1d.weight', 'target_model.mamba_blocks.7.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.A_log', 'target_model.mamba_blocks.7.mamba_fwd.D', 'target_model.mamba_blocks.7.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.A_log', 'target_model.mamba_blocks.7.mamba_bwd.D', 'target_model.mamba_blocks.7.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.7.out_proj.weight', 'target_model.mamba_blocks.7.norm.weight', 'target_model.mamba_blocks.7.norm.bias', 'target_model.norm_f.weight', 'target_model.norm_f.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = \"finetune_weight/pretrain_epoch020.pt\"\n",
    "state_dict = torch.load(weight_path, map_location=DEVICE)\n",
    "model_state = state_dict[\"model_state\"]\n",
    "\n",
    "model.backbone.load_state_dict(model_state, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "107f2f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['cls_token', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'mamba_blocks.0.in_proj.weight', 'mamba_blocks.0.conv1d.weight', 'mamba_blocks.0.conv1d.bias', 'mamba_blocks.0.mamba_fwd.A_log', 'mamba_blocks.0.mamba_fwd.D', 'mamba_blocks.0.mamba_fwd.in_proj.weight', 'mamba_blocks.0.mamba_fwd.conv1d.weight', 'mamba_blocks.0.mamba_fwd.conv1d.bias', 'mamba_blocks.0.mamba_fwd.x_proj.weight', 'mamba_blocks.0.mamba_fwd.dt_proj.weight', 'mamba_blocks.0.mamba_fwd.dt_proj.bias', 'mamba_blocks.0.mamba_fwd.out_proj.weight', 'mamba_blocks.0.mamba_bwd.A_log', 'mamba_blocks.0.mamba_bwd.D', 'mamba_blocks.0.mamba_bwd.in_proj.weight', 'mamba_blocks.0.mamba_bwd.conv1d.weight', 'mamba_blocks.0.mamba_bwd.conv1d.bias', 'mamba_blocks.0.mamba_bwd.x_proj.weight', 'mamba_blocks.0.mamba_bwd.dt_proj.weight', 'mamba_blocks.0.mamba_bwd.dt_proj.bias', 'mamba_blocks.0.mamba_bwd.out_proj.weight', 'mamba_blocks.0.out_proj.weight', 'mamba_blocks.0.norm.weight', 'mamba_blocks.0.norm.bias', 'mamba_blocks.1.in_proj.weight', 'mamba_blocks.1.conv1d.weight', 'mamba_blocks.1.conv1d.bias', 'mamba_blocks.1.mamba_fwd.A_log', 'mamba_blocks.1.mamba_fwd.D', 'mamba_blocks.1.mamba_fwd.in_proj.weight', 'mamba_blocks.1.mamba_fwd.conv1d.weight', 'mamba_blocks.1.mamba_fwd.conv1d.bias', 'mamba_blocks.1.mamba_fwd.x_proj.weight', 'mamba_blocks.1.mamba_fwd.dt_proj.weight', 'mamba_blocks.1.mamba_fwd.dt_proj.bias', 'mamba_blocks.1.mamba_fwd.out_proj.weight', 'mamba_blocks.1.mamba_bwd.A_log', 'mamba_blocks.1.mamba_bwd.D', 'mamba_blocks.1.mamba_bwd.in_proj.weight', 'mamba_blocks.1.mamba_bwd.conv1d.weight', 'mamba_blocks.1.mamba_bwd.conv1d.bias', 'mamba_blocks.1.mamba_bwd.x_proj.weight', 'mamba_blocks.1.mamba_bwd.dt_proj.weight', 'mamba_blocks.1.mamba_bwd.dt_proj.bias', 'mamba_blocks.1.mamba_bwd.out_proj.weight', 'mamba_blocks.1.out_proj.weight', 'mamba_blocks.1.norm.weight', 'mamba_blocks.1.norm.bias', 'mamba_blocks.2.in_proj.weight', 'mamba_blocks.2.conv1d.weight', 'mamba_blocks.2.conv1d.bias', 'mamba_blocks.2.mamba_fwd.A_log', 'mamba_blocks.2.mamba_fwd.D', 'mamba_blocks.2.mamba_fwd.in_proj.weight', 'mamba_blocks.2.mamba_fwd.conv1d.weight', 'mamba_blocks.2.mamba_fwd.conv1d.bias', 'mamba_blocks.2.mamba_fwd.x_proj.weight', 'mamba_blocks.2.mamba_fwd.dt_proj.weight', 'mamba_blocks.2.mamba_fwd.dt_proj.bias', 'mamba_blocks.2.mamba_fwd.out_proj.weight', 'mamba_blocks.2.mamba_bwd.A_log', 'mamba_blocks.2.mamba_bwd.D', 'mamba_blocks.2.mamba_bwd.in_proj.weight', 'mamba_blocks.2.mamba_bwd.conv1d.weight', 'mamba_blocks.2.mamba_bwd.conv1d.bias', 'mamba_blocks.2.mamba_bwd.x_proj.weight', 'mamba_blocks.2.mamba_bwd.dt_proj.weight', 'mamba_blocks.2.mamba_bwd.dt_proj.bias', 'mamba_blocks.2.mamba_bwd.out_proj.weight', 'mamba_blocks.2.out_proj.weight', 'mamba_blocks.2.norm.weight', 'mamba_blocks.2.norm.bias', 'mamba_blocks.3.in_proj.weight', 'mamba_blocks.3.conv1d.weight', 'mamba_blocks.3.conv1d.bias', 'mamba_blocks.3.mamba_fwd.A_log', 'mamba_blocks.3.mamba_fwd.D', 'mamba_blocks.3.mamba_fwd.in_proj.weight', 'mamba_blocks.3.mamba_fwd.conv1d.weight', 'mamba_blocks.3.mamba_fwd.conv1d.bias', 'mamba_blocks.3.mamba_fwd.x_proj.weight', 'mamba_blocks.3.mamba_fwd.dt_proj.weight', 'mamba_blocks.3.mamba_fwd.dt_proj.bias', 'mamba_blocks.3.mamba_fwd.out_proj.weight', 'mamba_blocks.3.mamba_bwd.A_log', 'mamba_blocks.3.mamba_bwd.D', 'mamba_blocks.3.mamba_bwd.in_proj.weight', 'mamba_blocks.3.mamba_bwd.conv1d.weight', 'mamba_blocks.3.mamba_bwd.conv1d.bias', 'mamba_blocks.3.mamba_bwd.x_proj.weight', 'mamba_blocks.3.mamba_bwd.dt_proj.weight', 'mamba_blocks.3.mamba_bwd.dt_proj.bias', 'mamba_blocks.3.mamba_bwd.out_proj.weight', 'mamba_blocks.3.out_proj.weight', 'mamba_blocks.3.norm.weight', 'mamba_blocks.3.norm.bias', 'mamba_blocks.4.in_proj.weight', 'mamba_blocks.4.conv1d.weight', 'mamba_blocks.4.conv1d.bias', 'mamba_blocks.4.mamba_fwd.A_log', 'mamba_blocks.4.mamba_fwd.D', 'mamba_blocks.4.mamba_fwd.in_proj.weight', 'mamba_blocks.4.mamba_fwd.conv1d.weight', 'mamba_blocks.4.mamba_fwd.conv1d.bias', 'mamba_blocks.4.mamba_fwd.x_proj.weight', 'mamba_blocks.4.mamba_fwd.dt_proj.weight', 'mamba_blocks.4.mamba_fwd.dt_proj.bias', 'mamba_blocks.4.mamba_fwd.out_proj.weight', 'mamba_blocks.4.mamba_bwd.A_log', 'mamba_blocks.4.mamba_bwd.D', 'mamba_blocks.4.mamba_bwd.in_proj.weight', 'mamba_blocks.4.mamba_bwd.conv1d.weight', 'mamba_blocks.4.mamba_bwd.conv1d.bias', 'mamba_blocks.4.mamba_bwd.x_proj.weight', 'mamba_blocks.4.mamba_bwd.dt_proj.weight', 'mamba_blocks.4.mamba_bwd.dt_proj.bias', 'mamba_blocks.4.mamba_bwd.out_proj.weight', 'mamba_blocks.4.out_proj.weight', 'mamba_blocks.4.norm.weight', 'mamba_blocks.4.norm.bias', 'mamba_blocks.5.in_proj.weight', 'mamba_blocks.5.conv1d.weight', 'mamba_blocks.5.conv1d.bias', 'mamba_blocks.5.mamba_fwd.A_log', 'mamba_blocks.5.mamba_fwd.D', 'mamba_blocks.5.mamba_fwd.in_proj.weight', 'mamba_blocks.5.mamba_fwd.conv1d.weight', 'mamba_blocks.5.mamba_fwd.conv1d.bias', 'mamba_blocks.5.mamba_fwd.x_proj.weight', 'mamba_blocks.5.mamba_fwd.dt_proj.weight', 'mamba_blocks.5.mamba_fwd.dt_proj.bias', 'mamba_blocks.5.mamba_fwd.out_proj.weight', 'mamba_blocks.5.mamba_bwd.A_log', 'mamba_blocks.5.mamba_bwd.D', 'mamba_blocks.5.mamba_bwd.in_proj.weight', 'mamba_blocks.5.mamba_bwd.conv1d.weight', 'mamba_blocks.5.mamba_bwd.conv1d.bias', 'mamba_blocks.5.mamba_bwd.x_proj.weight', 'mamba_blocks.5.mamba_bwd.dt_proj.weight', 'mamba_blocks.5.mamba_bwd.dt_proj.bias', 'mamba_blocks.5.mamba_bwd.out_proj.weight', 'mamba_blocks.5.out_proj.weight', 'mamba_blocks.5.norm.weight', 'mamba_blocks.5.norm.bias', 'mamba_blocks.6.in_proj.weight', 'mamba_blocks.6.conv1d.weight', 'mamba_blocks.6.conv1d.bias', 'mamba_blocks.6.mamba_fwd.A_log', 'mamba_blocks.6.mamba_fwd.D', 'mamba_blocks.6.mamba_fwd.in_proj.weight', 'mamba_blocks.6.mamba_fwd.conv1d.weight', 'mamba_blocks.6.mamba_fwd.conv1d.bias', 'mamba_blocks.6.mamba_fwd.x_proj.weight', 'mamba_blocks.6.mamba_fwd.dt_proj.weight', 'mamba_blocks.6.mamba_fwd.dt_proj.bias', 'mamba_blocks.6.mamba_fwd.out_proj.weight', 'mamba_blocks.6.mamba_bwd.A_log', 'mamba_blocks.6.mamba_bwd.D', 'mamba_blocks.6.mamba_bwd.in_proj.weight', 'mamba_blocks.6.mamba_bwd.conv1d.weight', 'mamba_blocks.6.mamba_bwd.conv1d.bias', 'mamba_blocks.6.mamba_bwd.x_proj.weight', 'mamba_blocks.6.mamba_bwd.dt_proj.weight', 'mamba_blocks.6.mamba_bwd.dt_proj.bias', 'mamba_blocks.6.mamba_bwd.out_proj.weight', 'mamba_blocks.6.out_proj.weight', 'mamba_blocks.6.norm.weight', 'mamba_blocks.6.norm.bias', 'mamba_blocks.7.in_proj.weight', 'mamba_blocks.7.conv1d.weight', 'mamba_blocks.7.conv1d.bias', 'mamba_blocks.7.mamba_fwd.A_log', 'mamba_blocks.7.mamba_fwd.D', 'mamba_blocks.7.mamba_fwd.in_proj.weight', 'mamba_blocks.7.mamba_fwd.conv1d.weight', 'mamba_blocks.7.mamba_fwd.conv1d.bias', 'mamba_blocks.7.mamba_fwd.x_proj.weight', 'mamba_blocks.7.mamba_fwd.dt_proj.weight', 'mamba_blocks.7.mamba_fwd.dt_proj.bias', 'mamba_blocks.7.mamba_fwd.out_proj.weight', 'mamba_blocks.7.mamba_bwd.A_log', 'mamba_blocks.7.mamba_bwd.D', 'mamba_blocks.7.mamba_bwd.in_proj.weight', 'mamba_blocks.7.mamba_bwd.conv1d.weight', 'mamba_blocks.7.mamba_bwd.conv1d.bias', 'mamba_blocks.7.mamba_bwd.x_proj.weight', 'mamba_blocks.7.mamba_bwd.dt_proj.weight', 'mamba_blocks.7.mamba_bwd.dt_proj.bias', 'mamba_blocks.7.mamba_bwd.out_proj.weight', 'mamba_blocks.7.out_proj.weight', 'mamba_blocks.7.norm.weight', 'mamba_blocks.7.norm.bias', 'norm_f.weight', 'norm_f.bias', 'target_model.cls_token', 'target_model.patch_embed.proj.weight', 'target_model.patch_embed.proj.bias', 'target_model.mamba_blocks.0.in_proj.weight', 'target_model.mamba_blocks.0.conv1d.weight', 'target_model.mamba_blocks.0.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.A_log', 'target_model.mamba_blocks.0.mamba_fwd.D', 'target_model.mamba_blocks.0.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.A_log', 'target_model.mamba_blocks.0.mamba_bwd.D', 'target_model.mamba_blocks.0.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.0.out_proj.weight', 'target_model.mamba_blocks.0.norm.weight', 'target_model.mamba_blocks.0.norm.bias', 'target_model.mamba_blocks.1.in_proj.weight', 'target_model.mamba_blocks.1.conv1d.weight', 'target_model.mamba_blocks.1.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.A_log', 'target_model.mamba_blocks.1.mamba_fwd.D', 'target_model.mamba_blocks.1.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.A_log', 'target_model.mamba_blocks.1.mamba_bwd.D', 'target_model.mamba_blocks.1.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.1.out_proj.weight', 'target_model.mamba_blocks.1.norm.weight', 'target_model.mamba_blocks.1.norm.bias', 'target_model.mamba_blocks.2.in_proj.weight', 'target_model.mamba_blocks.2.conv1d.weight', 'target_model.mamba_blocks.2.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.A_log', 'target_model.mamba_blocks.2.mamba_fwd.D', 'target_model.mamba_blocks.2.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.A_log', 'target_model.mamba_blocks.2.mamba_bwd.D', 'target_model.mamba_blocks.2.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.2.out_proj.weight', 'target_model.mamba_blocks.2.norm.weight', 'target_model.mamba_blocks.2.norm.bias', 'target_model.mamba_blocks.3.in_proj.weight', 'target_model.mamba_blocks.3.conv1d.weight', 'target_model.mamba_blocks.3.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.A_log', 'target_model.mamba_blocks.3.mamba_fwd.D', 'target_model.mamba_blocks.3.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.A_log', 'target_model.mamba_blocks.3.mamba_bwd.D', 'target_model.mamba_blocks.3.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.3.out_proj.weight', 'target_model.mamba_blocks.3.norm.weight', 'target_model.mamba_blocks.3.norm.bias', 'target_model.mamba_blocks.4.in_proj.weight', 'target_model.mamba_blocks.4.conv1d.weight', 'target_model.mamba_blocks.4.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.A_log', 'target_model.mamba_blocks.4.mamba_fwd.D', 'target_model.mamba_blocks.4.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.A_log', 'target_model.mamba_blocks.4.mamba_bwd.D', 'target_model.mamba_blocks.4.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.4.out_proj.weight', 'target_model.mamba_blocks.4.norm.weight', 'target_model.mamba_blocks.4.norm.bias', 'target_model.mamba_blocks.5.in_proj.weight', 'target_model.mamba_blocks.5.conv1d.weight', 'target_model.mamba_blocks.5.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.A_log', 'target_model.mamba_blocks.5.mamba_fwd.D', 'target_model.mamba_blocks.5.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.A_log', 'target_model.mamba_blocks.5.mamba_bwd.D', 'target_model.mamba_blocks.5.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.5.out_proj.weight', 'target_model.mamba_blocks.5.norm.weight', 'target_model.mamba_blocks.5.norm.bias', 'target_model.mamba_blocks.6.in_proj.weight', 'target_model.mamba_blocks.6.conv1d.weight', 'target_model.mamba_blocks.6.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.A_log', 'target_model.mamba_blocks.6.mamba_fwd.D', 'target_model.mamba_blocks.6.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.A_log', 'target_model.mamba_blocks.6.mamba_bwd.D', 'target_model.mamba_blocks.6.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.6.out_proj.weight', 'target_model.mamba_blocks.6.norm.weight', 'target_model.mamba_blocks.6.norm.bias', 'target_model.mamba_blocks.7.in_proj.weight', 'target_model.mamba_blocks.7.conv1d.weight', 'target_model.mamba_blocks.7.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.A_log', 'target_model.mamba_blocks.7.mamba_fwd.D', 'target_model.mamba_blocks.7.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.A_log', 'target_model.mamba_blocks.7.mamba_bwd.D', 'target_model.mamba_blocks.7.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.7.out_proj.weight', 'target_model.mamba_blocks.7.norm.weight', 'target_model.mamba_blocks.7.norm.bias', 'target_model.norm_f.weight', 'target_model.norm_f.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state = state_dict[\"model_state\"]\n",
    "model_state.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ffd9f",
   "metadata": {},
   "source": [
    "### Loading Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9457468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lr_scheduler import CosineLRScheduler\n",
    "\n",
    "try:\n",
    "    from eegdash.dataset import EEGChallengeDataset\n",
    "    from eegdash.hbn.windows import (\n",
    "        annotate_trials_with_target,\n",
    "        add_aux_anchors,\n",
    "        add_extras_columns,\n",
    "        keep_only_recordings_with,\n",
    "    )\n",
    "except Exception as e:\n",
    "    EEGChallengeDataset = None\n",
    "\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_windows_from_events\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "import torch.nn as nn\n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "import joblib\n",
    "from braindecode.datasets.base import EEGWindowsDataset, BaseConcatDataset, BaseDataset\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2c337832",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"LOL_DATASET/LOL_DATASET/HBN_DATA_FULL/\"\n",
    "RELEASES = [\"R1\", \"R2\"]\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SFREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2270bbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=256722;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=321138;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=107438;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=806931;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_datasets = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    name_folder = f\"{rel}_mini_L100_bdf\" \n",
    "    cache_dir = Path(DATA_PATH) / name_folder \n",
    "\n",
    "    dataset = EEGChallengeDataset(\n",
    "        cache_dir = cache_dir,\n",
    "        task = \"contrastChangeDetection\",\n",
    "        mini = True,\n",
    "        download = False,\n",
    "        release = rel,\n",
    "        description_fields = [\n",
    "            \"subject\",\n",
    "            \"session\",\n",
    "            \"run\",\n",
    "            \"task\",\n",
    "            \"age\",\n",
    "            \"gender\",\n",
    "            \"sex\",\n",
    "            \"p_factor\",\n",
    "            # \"internalizing\",\n",
    "            # \"externalizing\",\n",
    "            # \"ehq_total\",\n",
    "            # \"commercial_use\",\n",
    "            # \"full_pheno\",\n",
    "            # \"attention\"\n",
    "            \n",
    "        ],\n",
    "\n",
    "        \n",
    "    )\n",
    "\n",
    "    all_datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900abc6",
   "metadata": {},
   "source": [
    " ## 2. Wrap the data into a PyTorch-compatible dataset\n",
    "\n",
    " The class below defines a dataset wrapper that will extract 2-second windows,\n",
    " uniformly sampled over the whole signal. In addition, it will add useful information\n",
    " about the extracted windows, such as the externalizing factor, the subject or the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6e845ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWrapper(BaseDataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset: EEGWindowsDataset,\n",
    "        crop_size_samples: int,\n",
    "        target_name: str = \"externalizing\",\n",
    "        seed = None,\n",
    "    ):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.crop_size_samples = crop_size_samples\n",
    "        self.target_name = target_name\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, _, crop_inds = self.dataset[idx]\n",
    "\n",
    "        target = self.dataset.description[self.target_name]\n",
    "        print(target)\n",
    "        target = float(target)\n",
    "\n",
    "        # Additional information\n",
    "        infos = {\n",
    "            \"subject\": self.dataset.description[\"subject\"],\n",
    "            \"sex\": self.dataset.description[\"sex\"],\n",
    "            \"age\": float(self.dataset.description[\"age\"]),\n",
    "            \"task\": self.dataset.description[\"task\"],\n",
    "            \"session\": self.dataset.description.get(\"session\", None) or \"\",\n",
    "            \"run\": self.dataset.description.get(\"run\", None) or \"\",\n",
    "        }\n",
    "\n",
    "        # Random cropping the EEG waves to the size of crop_size_samples \n",
    "        i_window_in_trial, i_start, i_stop = crop_inds\n",
    "        assert i_stop - i_start >= self.crop_size_samples, f\"{i_stop=} {i_start=}\"\n",
    "        start_offset = self.rng.integers(0, i_stop - i_start - self.crop_size_samples + 1)\n",
    "        i_start = i_start + start_offset \n",
    "        i_stop  = i_start + self.crop_size_samples\n",
    "\n",
    "        return X, target, (i_window_in_trial, i_start, i_stop), infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56e3b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "import math\n",
    "\n",
    "preproc_dir = Path(\"preprocessed_dataset\")\n",
    "preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "list_windows = []\n",
    "\n",
    "for idx, data in enumerate(all_datasets):\n",
    "    filter_data = BaseConcatDataset(\n",
    "       [\n",
    "            ds \n",
    "            for ds in data.datasets\n",
    "            if ds.raw.n_times >= 4 * SFREQ\n",
    "            and len(ds.raw.ch_names) == 129\n",
    "            and not math.isnan(ds.description[\"p_factor\"])\n",
    "       ] \n",
    "    )\n",
    "\n",
    "    # Create 4-seconds windows with 2-seconds stride\n",
    "    windows_ds = create_fixed_length_windows(\n",
    "        filter_data,\n",
    "        window_size_samples=4 * SFREQ,\n",
    "        window_stride_samples=2 * SFREQ,\n",
    "        drop_last_window=True,\n",
    "    )\n",
    "    windows_ds = BaseConcatDataset(\n",
    "            [DatasetWrapper(ds, crop_size_samples=2 * SFREQ) for ds in windows_ds.datasets]\n",
    "    )\n",
    "\n",
    "    list_windows.append(windows_ds)\n",
    "\n",
    "    save_path = preproc_dir / f\"{RELEASES[idx]}_windows.pkl\"\n",
    "    joblib.dump(windows_ds, save_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3b3fd357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 6.4831329e-05, -6.1362621e-06,  1.8794045e-08, ...,\n",
       "         -5.5702254e-05, -5.8715075e-05, -5.6652494e-05],\n",
       "        [ 2.9976351e-05, -3.7022841e-05, -2.9796010e-05, ...,\n",
       "         -9.4364950e-05, -1.0916590e-04, -1.0272729e-04],\n",
       "        [ 1.0300881e-05, -4.5629182e-05, -3.3451066e-05, ...,\n",
       "          3.5722020e-05,  3.0152774e-05,  3.3893011e-05],\n",
       "        ...,\n",
       "        [ 8.1039987e-05,  5.8947244e-05,  6.8126959e-05, ...,\n",
       "         -1.8899624e-05, -7.7549084e-06, -9.7040192e-06],\n",
       "        [ 7.7256365e-05,  1.5659152e-05,  2.8310096e-05, ...,\n",
       "         -2.1114942e-05, -1.2811515e-05, -1.4344756e-05],\n",
       "        [ 5.0000005e-13,  5.0000005e-13,  5.0000005e-13, ...,\n",
       "          5.0000005e-13,  5.0000005e-13,  5.0000005e-13]],\n",
       "       shape=(129, 400), dtype=float32),\n",
       " 0.62,\n",
       " (0, np.int64(80), np.int64(280)),\n",
       " {'subject': 'NDARAB793GL3',\n",
       "  'sex': 'M',\n",
       "  'age': 13.4391,\n",
       "  'task': 'contrastChangeDetection',\n",
       "  'session': '',\n",
       "  'run': '1'})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded1401",
   "metadata": {},
   "source": [
    "#### Testing the whole procedure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "94a0d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import joblib, math, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from braindecode.datasets.base import EEGWindowsDataset, BaseConcatDataset, BaseDataset\n",
    "from tqdm.notebook import tqdm\n",
    "import typing\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e49aa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SFREQ = 100\n",
    "CROP_SEC = 2\n",
    "WINDOW_SEC = 4\n",
    "STRIDE_SEC = 2\n",
    "\n",
    "DATA_PATH = Path(\"LOL_DATASET/LOL_DATASET/HBN_DATA_FULL/\")\n",
    "RELEASES = [\"R1\", \"R2\", \"R3\"]\n",
    "\n",
    "TASK_NAMES = [\n",
    "    \"contrastChangeDetection\"\n",
    "    # \"RestingState\", \"DespicableMe\", \"DiaryOfAWimpyKid\", \"FunwithFractals\",\n",
    "    # \"ThePresent\", \"contrastChangeDetection\", \"seqLearning6target\",\n",
    "    # \"seqLearning8target\", \"surroundSupp\", \"symbolSearch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200936ef",
   "metadata": {},
   "source": [
    " 2. Meta Encoder (task + sex + age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5b43e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaEncoder:\n",
    "    def __init__(self):\n",
    "        self.task_enc = LabelEncoder()\n",
    "        self.sex_enc = LabelEncoder()\n",
    "        self.age_scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, metas: typing.List[dict]):\n",
    "        tasks = [m[\"task\"] for m in metas]\n",
    "        sexes = [m[\"sex\"] for m in metas]\n",
    "        ages = [[m[\"age\"]] for m in metas]\n",
    "        self.task_enc.fit(tasks)\n",
    "        self.sex_enc.fit(sexes)\n",
    "        self.age_scaler.fit(ages)\n",
    "        self.dim = len(self.task_enc.classes_) + len(self.sex_enc.classes_) + 1\n",
    "        return self\n",
    "\n",
    "    def transform(self, meta: dict) -> torch.Tensor:\n",
    "        t = self.task_enc.transform([meta[\"task\"]])[0]\n",
    "        s = self.sex_enc.transform([meta[\"sex\"]])[0]\n",
    "        a = self.age_scaler.transform([[meta[\"age\"]]])[0, 0]\n",
    "        vec = torch.zeros(self.dim, dtype=torch.float32)\n",
    "        vec[t] = 1.0\n",
    "        vec[len(self.task_enc.classes_) + s] = 1.0\n",
    "        vec[-1] = a\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "12ab1cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=181350;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=546155;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=324733;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=130650;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=709920;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=679383;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = []\n",
    "meta_for_encoder = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    folder = f\"{rel}_mini_L100_bdf\"\n",
    "    cache_dir = DATA_PATH / folder\n",
    "    for task in TASK_NAMES:\n",
    "        ds = EEGChallengeDataset(\n",
    "            cache_dir=cache_dir,\n",
    "            task=task,\n",
    "            mini=True,\n",
    "            download=False,\n",
    "            release=rel,\n",
    "            description_fields=[\n",
    "                \"subject\",\n",
    "                \"session\",\n",
    "                \"run\",\n",
    "                \"task\",\n",
    "                \"age\",\n",
    "                \"gender\",\n",
    "                \"sex\",\n",
    "                \"p_factor\",\n",
    "            ],\n",
    "        )\n",
    "        raw_datasets.append(ds)\n",
    "        for sub_ds in ds.datasets:\n",
    "            d = sub_ds.description\n",
    "            if not math.isnan(d.get(\"externalizing\", math.nan)):\n",
    "                meta_for_encoder.append({\n",
    "                    \"task\": d[\"task\"],\n",
    "                    \"sex\": d[\"sex\"],\n",
    "                    \"age\": float(d[\"age\"]),\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f492e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta embedding dim: 4\n"
     ]
    }
   ],
   "source": [
    "# Fit global encoder\n",
    "meta_encoder = MetaEncoder().fit(meta_for_encoder)\n",
    "META_DIM = meta_encoder.dim\n",
    "print(f\"Meta embedding dim: {META_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "25b64516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropMetaWrapper(BaseDataset):\n",
    "    def __init__(self, windows_ds, \n",
    "                        crop_samples, \n",
    "                        meta_encoder, \n",
    "                        target_name=\"externalizing\"):\n",
    "        \n",
    "        self.windows_ds = windows_ds\n",
    "        self.crop_samples = crop_samples\n",
    "        self.meta_encoder = meta_encoder\n",
    "        self.target_name = target_name\n",
    "        self.rng = np.random.default_rng(2025)  # fixed seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows_ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, _, crop_inds = self.windows_ds[idx]  # X: (C, 4*SFREQ)\n",
    "\n",
    "        # Target\n",
    "        target = float(self.windows_ds.description[self.target_name])\n",
    "\n",
    "        # Meta\n",
    "        desc = self.windows_ds.description\n",
    "        meta_dict = {\n",
    "            \"task\": desc[\"task\"],\n",
    "            \"sex\": desc[\"sex\"],\n",
    "            \"age\": float(desc[\"age\"]),\n",
    "        }\n",
    "        meta_vec = self.meta_encoder.transform(meta_dict)\n",
    "\n",
    "        # Random 2s crop\n",
    "        i_win, i_start, i_stop = crop_inds\n",
    "\n",
    "\n",
    "        assert i_stop - i_start >= self.crop_samples\n",
    "\n",
    "        # FIXED: .integers instead of .randint\n",
    "        offset = self.rng.integers(0, i_stop - i_start - self.crop_samples + 1)\n",
    "        i_start = i_start + offset\n",
    "        i_stop = i_start + self.crop_samples\n",
    "        X_crop = X[:, offset : offset + self.crop_samples]  # (C, 2*SFREQ)\n",
    "\n",
    "        # Infos\n",
    "        infos = {\n",
    "            \"subject\": desc[\"subject\"],\n",
    "            \"session\": desc.get(\"session\", \"\"),\n",
    "            \"run\": desc.get(\"run\", \"\"),\n",
    "            \"task\": desc[\"task\"],\n",
    "            \"sex\": desc[\"sex\"],\n",
    "            \"age\": float(desc[\"age\"]),\n",
    "        }\n",
    "\n",
    "        return torch.tensor(X_crop), meta_vec, target, (i_win, i_start, i_stop), infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d8019d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dir = Path(\"preprocessed_dataset\")\n",
    "preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "list_windows = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    rel_raw = [ds for ds in raw_datasets if ds.release == rel]\n",
    "    filtered = BaseConcatDataset([\n",
    "        sub_ds for ds in rel_raw for sub_ds in ds.datasets\n",
    "        if (sub_ds.raw.n_times >= 4 * SFREQ\n",
    "            and len(sub_ds.raw.ch_names) == 129\n",
    "            and not math.isnan(sub_ds.description.get(\"externalizing\", math.nan)))\n",
    "    ])\n",
    "    windows = create_fixed_length_windows(\n",
    "        filtered,\n",
    "        window_size_samples= 4 * SFREQ,\n",
    "        window_stride_samples= 2 * SFREQ,\n",
    "        drop_last_window=True,\n",
    "    )\n",
    "    windows_ds = BaseConcatDataset(\n",
    "        [CropMetaWrapper(\n",
    "            ds, crop_samples=CROP_SEC * SFREQ, meta_encoder=meta_encoder\n",
    "        ) for ds in windows.datasets\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    list_windows.append(windows_ds)\n",
    "    joblib.dump(windows_ds, preproc_dir / f\"{rel}_windows.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2d8b98b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ccfe2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_windows = BaseConcatDataset(list_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cbd99a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37381"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrapped_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "4240e38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([129, 200])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, _, _, _, _ = wrapped_windows[5]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c00bb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RANDOM SPLIT BY LENGTH ===\n",
    "total_len = len(wrapped_windows)\n",
    "train_len = int(0.8 * total_len)\n",
    "valid_len = int(0.1 * total_len)\n",
    "test_len  = total_len - train_len - valid_len\n",
    "\n",
    "train_ds, valid_ds, test_ds = random_split(\n",
    "    wrapped_windows,\n",
    "    [train_len, valid_len, test_len],\n",
    "    generator=torch.Generator().manual_seed(2025)  # reproducible\n",
    ")\n",
    "\n",
    "# === DATALOADERS ===\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X, meta, y, wins, infos = zip(*batch)\n",
    "\n",
    "    return (\n",
    "        torch.stack(X),\n",
    "        torch.stack(meta),\n",
    "        torch.tensor(y, dtype=torch.float32).unsqueeze(1),\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "eb1f90f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 129, 200]), torch.Size([16, 4]), torch.Size([16, 1]))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch[0].shape, batch[1].shape, batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d90deb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetuneJEPAWithMeta(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int = 256,\n",
    "        n_layer: int = 8,\n",
    "        patch_size: int = 10,\n",
    "        meta_dim: int = META_DIM,        # ← from meta_encoder\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # 1. EEG Backbone (your JEPA-pretrained Mamba)\n",
    "        self.backbone = EegMambaJEPA(\n",
    "            d_model=d_model,\n",
    "            n_layer=n_layer,\n",
    "            n_channels=129,\n",
    "            patch_size=patch_size,\n",
    "        )\n",
    "\n",
    "        # 2. Meta Projection (meta → d_model)\n",
    "        self.meta_proj = nn.Sequential(\n",
    "            nn.Linear(meta_dim, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model),\n",
    "        )\n",
    "\n",
    "        # 3. Fusion + Head\n",
    "        self.fusion_norm = nn.LayerNorm(d_model * 2)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, eeg: torch.Tensor, meta: torch.Tensor):\n",
    "        \"\"\"\n",
    "        eeg:  (B, 129, 200)\n",
    "        meta: (B, META_DIM)\n",
    "        \"\"\"\n",
    "        # EEG → (B, d_model)\n",
    "        z_eeg = self.backbone(eeg)\n",
    "        print(z_eeg.shape)\n",
    "\n",
    "        # Meta → (B, d_model)\n",
    "        z_meta = self.meta_proj(meta)\n",
    "        print(z_meta.shape)\n",
    "\n",
    "        # Fuse\n",
    "        z = torch.cat([z_eeg, z_meta], dim=-1)   # (B, 2*d_model)\n",
    "        z = self.fusion_norm(z)\n",
    "\n",
    "        # Predict\n",
    "        out = self.head(z).squeeze(-1)           # (B,)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "19e2b9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 129, 0])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "919a083a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (0). Kernel size: (10). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m batch = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[32m      3\u001b[39m egg, meta, y = batch\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43megg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mFinetuneJEPAWithMeta.forward\u001b[39m\u001b[34m(self, eeg, meta)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03meeg:  (B, 129, 200)\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03mmeta: (B, META_DIM)\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# EEG → (B, d_model)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m z_eeg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(z_eeg.shape)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Meta → (B, d_model)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/quang/eeg_challenge/model/eegmamba_jamba.py:191\u001b[39m, in \u001b[36mEegMambaJEPA.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03mx: (B, C, T)\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03mreturns: (B, d_model)  -- embedding for CLS token\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# Embed patches\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, NumPatches, d_model)\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Prepend CLS token\u001b[39;00m\n\u001b[32m    194\u001b[39m x = \u001b[38;5;28mself\u001b[39m._prepend_cls_token(x)  \u001b[38;5;66;03m# (B, 1 + NumPatches, d_model)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/quang/eeg_challenge/model/eegmamba_jamba.py:26\u001b[39m, in \u001b[36mPatchEmbed.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, D_MODEL, NumPatches)\u001b[39;00m\n\u001b[32m     27\u001b[39m     x = x.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B, NumPatches, D_MODEL)\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/conv.py:371\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eeg_new/lib/python3.11/site-packages/torch/nn/modules/conv.py:366\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    356\u001b[39m         F.pad(\n\u001b[32m    357\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    365\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Calculated padded input size per channel: (0). Kernel size: (10). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "model = FinetuneJEPAWithMeta(d_model=256, meta_dim=META_DIM).to(DEVICE)\n",
    "batch = next(iter(train_loader))\n",
    "egg, meta, y = batch\n",
    "model(egg.to(DEVICE), meta.to(DEVICE)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc355cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
