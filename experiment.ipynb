{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61b7d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lr_scheduler import CosineLRScheduler\n",
    "\n",
    "try:\n",
    "    from eegdash.dataset import EEGChallengeDataset\n",
    "    from eegdash.hbn.windows import (\n",
    "        annotate_trials_with_target,\n",
    "        add_aux_anchors,\n",
    "        add_extras_columns,\n",
    "        keep_only_recordings_with,\n",
    "    )\n",
    "except Exception as e:\n",
    "    EEGChallengeDataset = None\n",
    "\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_windows_from_events\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "import torch.nn as nn\n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"LOL_DATASET/LOL_DATASET/HBN_DATA_FULL/\"\n",
    "RELEASES = [\"R1\", \"R2\", \"R3\"]\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b0b68ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=842128;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=116104;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=906093;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=20637;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭─────────────────────────────────────── EEG 2025 Competition Data Notice ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Downsampled from 500Hz to 100Hz                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Bandpass filtered (0.5-50 Hz)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For full preprocessing applied for competition details, see:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   <a href=\"https://github.com/eeg2025/downsample-datasets\" target=\"_blank\">https://github.com/eeg2025/downsample-datasets</a>                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The HBN dataset have some preprocessing applied by the HBN team:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   * Re-reference (Cz Channel)                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">IMPORTANT</span>: The data accessed via `EEGChallengeDataset` is <span style=\"text-decoration: underline\">NOT</span> identical to what you get from <a href=\"https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\" target=\"_blank\">EEGDashDataset</a>     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> directly.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> challenge data.                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080\">Source: EEGChallengeDataset</span><span style=\"color: #808000; text-decoration-color: #808000\"> ──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[33mEEG 2025 Competition Data Notice\u001b[0m\u001b[33m \u001b[0m\u001b[33m───────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m This object loads the HBN dataset that has been preprocessed for the EEG Challenge:                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Downsampled from 500Hz to 100Hz                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Bandpass filtered (0.5-50 Hz)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For full preprocessing applied for competition details, see:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   \u001b]8;id=853931;https://github.com/eeg2025/downsample-datasets\u001b\\https://github.com/eeg2025/downsample-datasets\u001b]8;;\u001b\\                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The HBN dataset have some preprocessing applied by the HBN team:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   * Re-reference (Cz Channel)                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \u001b[1;31mIMPORTANT\u001b[0m: The data accessed via `EEGChallengeDataset` is \u001b[4mNOT\u001b[0m identical to what you get from \u001b]8;id=365125;https://github.com/sccn/EEGDash/blob/develop/eegdash/api.py\u001b\\EEGDashDataset\u001b]8;;\u001b\\     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m directly.                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m If you are participating in the competition, always use `EEGChallengeDataset` to ensure consistency with the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m challenge data.                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[36mSource: EEGChallengeDataset\u001b[0m\u001b[33m \u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_dataset = []\n",
    "for rel in RELEASES:\n",
    "    name_folder = f\"{rel}_mini_L100_bdf\" \n",
    "    cache_dir = Path(DATA_PATH) / name_folder \n",
    "\n",
    "    dataset = EEGChallengeDataset(\n",
    "        cache_dir = cache_dir,\n",
    "        task = \"contrastChangeDetection\",\n",
    "        mini = True,\n",
    "        download = False,\n",
    "        release = rel\n",
    "    )\n",
    "\n",
    "    all_dataset.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82683afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<eegdash.dataset.dataset.EEGChallengeDataset at 0x7819ee614f90>,\n",
       " <eegdash.dataset.dataset.EEGChallengeDataset at 0x7819ece6cdd0>,\n",
       " <eegdash.dataset.dataset.EEGChallengeDataset at 0x7819ece7af10>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf160ee3",
   "metadata": {},
   "source": [
    "Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c799b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_LENS_S = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8eedbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_offline_preprocessors():\n",
    "    return [\n",
    "        Preprocessor(annotate_trials_with_target, \n",
    "                     target_field = \"rt_from_stimulus\", \n",
    "                     epoch_length = EPOCH_LENS_S, \n",
    "                     require_stimulus = True, \n",
    "                     require_response = True, \n",
    "                     apply_on_array = False),\n",
    "        Preprocessor(add_aux_anchors, apply_on_array=False),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c1264",
   "metadata": {},
   "source": [
    "This case we don't need to save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01da0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n",
      "Used Annotations descriptions: [np.str_('stimulus_anchor')]\n"
     ]
    }
   ],
   "source": [
    "preproc_dir = Path(\"preprocessed_dataset\")\n",
    "preproc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "list_windows = []\n",
    "\n",
    "ANCHOR = \"stimulus_anchor\"\n",
    "SHIFT_AFTER_STIM = 0.5\n",
    "WINDOW_LEN = 2.0\n",
    "SFREQ = 100\n",
    "\n",
    "preproc = build_offline_preprocessors()\n",
    "\n",
    "for i, dataset in enumerate(all_dataset):\n",
    "    preprocess(dataset, preproc, n_jobs = -1)\n",
    "\n",
    "    dataset = keep_only_recordings_with(ANCHOR, dataset)\n",
    "    windows = create_windows_from_events(\n",
    "        dataset, \n",
    "        mapping = {ANCHOR: 0},\n",
    "        trial_start_offset_samples = int(SHIFT_AFTER_STIM * SFREQ),                 # +0.5 s\n",
    "        trial_stop_offset_samples = int((SHIFT_AFTER_STIM + WINDOW_LEN) * SFREQ),   # +2.5 s\n",
    "        window_size_samples = int(WINDOW_LEN * SFREQ),\n",
    "        window_stride_samples = SFREQ,\n",
    "        preload=True,\n",
    "    )\n",
    "\n",
    "    windows = add_extras_columns(\n",
    "        windows,\n",
    "        dataset,\n",
    "        desc=ANCHOR,\n",
    "        keys=(\"target\", \"rt_from_stimulus\", \"rt_from_trialstart\",\n",
    "              \"stimulus_onset\", \"response_onset\", \"correct\", \"response_type\")\n",
    "    )\n",
    "\n",
    "    list_windows.append(windows)\n",
    "\n",
    "    save_path = preproc_dir / f\"{RELEASES[i]}_windows.pkl\"\n",
    "    joblib.dump(windows, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a02c1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_windows = []\n",
    "\n",
    "for rel in RELEASES:\n",
    "    load_path = preproc_dir / f\"{rel}_windows.pkl\"\n",
    "    windows = joblib.load(load_path)\n",
    "    load_windows.append(windows)\n",
    "\n",
    "all_windows = BaseConcatDataset(load_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a626c43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_window_in_trial</th>\n",
       "      <th>i_start_in_trial</th>\n",
       "      <th>i_stop_in_trial</th>\n",
       "      <th>target</th>\n",
       "      <th>rt_from_stimulus</th>\n",
       "      <th>rt_from_trialstart</th>\n",
       "      <th>stimulus_onset</th>\n",
       "      <th>response_onset</th>\n",
       "      <th>correct</th>\n",
       "      <th>response_type</th>\n",
       "      <th>...</th>\n",
       "      <th>thepresent</th>\n",
       "      <th>diaryofawimpykid</th>\n",
       "      <th>contrastchangedetection_1</th>\n",
       "      <th>contrastchangedetection_2</th>\n",
       "      <th>contrastchangedetection_3</th>\n",
       "      <th>surroundsupp_1</th>\n",
       "      <th>surroundsupp_2</th>\n",
       "      <th>seqlearning6target</th>\n",
       "      <th>seqlearning8target</th>\n",
       "      <th>symbolsearch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4278</td>\n",
       "      <td>4478</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>4.93</td>\n",
       "      <td>42.284</td>\n",
       "      <td>44.414</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4798</td>\n",
       "      <td>4998</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.96</td>\n",
       "      <td>4.76</td>\n",
       "      <td>47.484</td>\n",
       "      <td>49.444</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5478</td>\n",
       "      <td>5678</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.42</td>\n",
       "      <td>54.284</td>\n",
       "      <td>56.304</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6318</td>\n",
       "      <td>6518</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>7.72</td>\n",
       "      <td>62.684</td>\n",
       "      <td>64.404</td>\n",
       "      <td>1</td>\n",
       "      <td>right_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6838</td>\n",
       "      <td>7038</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>67.884</td>\n",
       "      <td>69.684</td>\n",
       "      <td>1</td>\n",
       "      <td>left_buttonPress</td>\n",
       "      <td>...</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>unavailable</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_window_in_trial  i_start_in_trial  i_stop_in_trial  target  \\\n",
       "0                  0              4278             4478    2.13   \n",
       "1                  0              4798             4998    1.96   \n",
       "2                  0              5478             5678    2.02   \n",
       "3                  0              6318             6518    1.72   \n",
       "4                  0              6838             7038     1.8   \n",
       "\n",
       "   rt_from_stimulus  rt_from_trialstart  stimulus_onset  response_onset  \\\n",
       "0              2.13                4.93          42.284          44.414   \n",
       "1              1.96                4.76          47.484          49.444   \n",
       "2              2.02                6.42          54.284          56.304   \n",
       "3              1.72                7.72          62.684          64.404   \n",
       "4               1.8                 4.6          67.884          69.684   \n",
       "\n",
       "   correct      response_type  ... thepresent diaryofawimpykid  \\\n",
       "0        1  right_buttonPress  ...  available        available   \n",
       "1        1  right_buttonPress  ...  available        available   \n",
       "2        1  right_buttonPress  ...  available        available   \n",
       "3        1  right_buttonPress  ...  available        available   \n",
       "4        1   left_buttonPress  ...  available        available   \n",
       "\n",
       "  contrastchangedetection_1  contrastchangedetection_2  \\\n",
       "0                 available                  available   \n",
       "1                 available                  available   \n",
       "2                 available                  available   \n",
       "3                 available                  available   \n",
       "4                 available                  available   \n",
       "\n",
       "  contrastchangedetection_3 surroundsupp_1  surroundsupp_2 seqlearning6target  \\\n",
       "0                 available      available       available        unavailable   \n",
       "1                 available      available       available        unavailable   \n",
       "2                 available      available       available        unavailable   \n",
       "3                 available      available       available        unavailable   \n",
       "4                 available      available       available        unavailable   \n",
       "\n",
       "  seqlearning8target  symbolsearch  \n",
       "0          available     available  \n",
       "1          available     available  \n",
       "2          available     available  \n",
       "3          available     available  \n",
       "4          available     available  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_windows.get_metadata().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d44240",
   "metadata": {},
   "source": [
    "#### Spliting the train test valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5b6d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = all_windows.get_metadata()\n",
    "subjects = list(meta['subject'].unique())\n",
    "\n",
    "valid_frac = 0.1\n",
    "test_frac = 0.1\n",
    "seed = 2025\n",
    "\n",
    "train_subj, valid_test_subject = train_test_split(subjects, test_size=(valid_frac + test_frac), random_state=check_random_state(seed), shuffle=True)\n",
    "valid_subj, test_subj = train_test_split(valid_test_subject, test_size=test_frac/(valid_frac+test_frac), random_state=check_random_state(seed+1), shuffle=True)\n",
    "\n",
    "subject_split = windows.split(\"subject\")\n",
    "train_sets = [ds for subj, ds in subject_split.items() if subj in train_subj]\n",
    "valid_sets = [ds for subj, ds in subject_split.items() if subj in valid_subj]\n",
    "test_sets = [ds for subj, ds in subject_split.items() if subj in test_subj]\n",
    "\n",
    "train_ds = BaseConcatDataset(train_sets)\n",
    "valid_ds = BaseConcatDataset(valid_sets)\n",
    "test_ds = BaseConcatDataset(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ddada97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "134\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(valid_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c8d00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastChangeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, braindecode_dataset):\n",
    "        self.dataset = braindecode_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y, _ = self.dataset[idx]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "train_dataset = ContrastChangeDataset(train_ds)\n",
    "valid_dataset = ContrastChangeDataset(valid_ds)\n",
    "test_dataset = ContrastChangeDataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49f66893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2222e-05,  5.1986e-06,  5.3049e-06,  ..., -8.8720e-07,\n",
       "           7.3418e-07, -9.9474e-07],\n",
       "         [ 1.1537e-05,  5.4671e-06,  5.5437e-06,  ..., -6.2149e-07,\n",
       "           1.2688e-06,  3.0214e-07],\n",
       "         [ 1.3410e-05,  6.8182e-06,  5.9050e-06,  ...,  8.5317e-07,\n",
       "           1.7593e-06,  8.2808e-07],\n",
       "         ...,\n",
       "         [-8.4166e-06, -1.0888e-05, -9.3056e-06,  ...,  6.8735e-06,\n",
       "           3.1253e-06,  1.5513e-06],\n",
       "         [-1.2049e-05, -1.4262e-05, -1.3558e-05,  ...,  9.3226e-06,\n",
       "           5.4775e-06,  2.9852e-06],\n",
       "         [ 5.0000e-13,  5.0000e-13,  5.0000e-13,  ...,  5.0000e-13,\n",
       "           5.0000e-13,  5.0000e-13]]),\n",
       " tensor([1.9580]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = train_dataset[0]\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4315bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f622c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 129, 200]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "first_batch[0].shape, first_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28971512",
   "metadata": {},
   "source": [
    "Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd4945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/eeg_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "from model.eegmamba_jamba import EegMambaJEPA\n",
    "\n",
    "class FinetuneJEPA(nn.Module):\n",
    "    \"\"\"Simple wrapper: EegMambaJEPA backbone -> linear regression head.\"\"\"\n",
    "    def __init__(self, \n",
    "                 n_chans: int = 129, \n",
    "                 d_model: int = 256, \n",
    "                 n_layer: int = 8, \n",
    "                 patch_size: int = 10\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.backbone = EegMambaJEPA(\n",
    "            d_model=d_model, \n",
    "            n_layer=n_layer, \n",
    "            n_channels=n_chans, \n",
    "            patch_size=patch_size\n",
    "            )\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, C, T)\n",
    "        z = self.backbone(x)  # (B, d_model)\n",
    "        out = self.head(z)    # (B, 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2605e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = FinetuneJEPA(n_chans=129, d_model=256, n_layer=8, patch_size=10)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31e1ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['target_model.cls_token', 'target_model.patch_embed.proj.weight', 'target_model.patch_embed.proj.bias', 'target_model.mamba_blocks.0.in_proj.weight', 'target_model.mamba_blocks.0.conv1d.weight', 'target_model.mamba_blocks.0.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.A_log', 'target_model.mamba_blocks.0.mamba_fwd.D', 'target_model.mamba_blocks.0.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.A_log', 'target_model.mamba_blocks.0.mamba_bwd.D', 'target_model.mamba_blocks.0.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.0.out_proj.weight', 'target_model.mamba_blocks.0.norm.weight', 'target_model.mamba_blocks.0.norm.bias', 'target_model.mamba_blocks.1.in_proj.weight', 'target_model.mamba_blocks.1.conv1d.weight', 'target_model.mamba_blocks.1.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.A_log', 'target_model.mamba_blocks.1.mamba_fwd.D', 'target_model.mamba_blocks.1.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.A_log', 'target_model.mamba_blocks.1.mamba_bwd.D', 'target_model.mamba_blocks.1.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.1.out_proj.weight', 'target_model.mamba_blocks.1.norm.weight', 'target_model.mamba_blocks.1.norm.bias', 'target_model.mamba_blocks.2.in_proj.weight', 'target_model.mamba_blocks.2.conv1d.weight', 'target_model.mamba_blocks.2.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.A_log', 'target_model.mamba_blocks.2.mamba_fwd.D', 'target_model.mamba_blocks.2.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.A_log', 'target_model.mamba_blocks.2.mamba_bwd.D', 'target_model.mamba_blocks.2.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.2.out_proj.weight', 'target_model.mamba_blocks.2.norm.weight', 'target_model.mamba_blocks.2.norm.bias', 'target_model.mamba_blocks.3.in_proj.weight', 'target_model.mamba_blocks.3.conv1d.weight', 'target_model.mamba_blocks.3.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.A_log', 'target_model.mamba_blocks.3.mamba_fwd.D', 'target_model.mamba_blocks.3.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.A_log', 'target_model.mamba_blocks.3.mamba_bwd.D', 'target_model.mamba_blocks.3.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.3.out_proj.weight', 'target_model.mamba_blocks.3.norm.weight', 'target_model.mamba_blocks.3.norm.bias', 'target_model.mamba_blocks.4.in_proj.weight', 'target_model.mamba_blocks.4.conv1d.weight', 'target_model.mamba_blocks.4.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.A_log', 'target_model.mamba_blocks.4.mamba_fwd.D', 'target_model.mamba_blocks.4.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.A_log', 'target_model.mamba_blocks.4.mamba_bwd.D', 'target_model.mamba_blocks.4.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.4.out_proj.weight', 'target_model.mamba_blocks.4.norm.weight', 'target_model.mamba_blocks.4.norm.bias', 'target_model.mamba_blocks.5.in_proj.weight', 'target_model.mamba_blocks.5.conv1d.weight', 'target_model.mamba_blocks.5.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.A_log', 'target_model.mamba_blocks.5.mamba_fwd.D', 'target_model.mamba_blocks.5.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.A_log', 'target_model.mamba_blocks.5.mamba_bwd.D', 'target_model.mamba_blocks.5.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.5.out_proj.weight', 'target_model.mamba_blocks.5.norm.weight', 'target_model.mamba_blocks.5.norm.bias', 'target_model.mamba_blocks.6.in_proj.weight', 'target_model.mamba_blocks.6.conv1d.weight', 'target_model.mamba_blocks.6.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.A_log', 'target_model.mamba_blocks.6.mamba_fwd.D', 'target_model.mamba_blocks.6.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.A_log', 'target_model.mamba_blocks.6.mamba_bwd.D', 'target_model.mamba_blocks.6.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.6.out_proj.weight', 'target_model.mamba_blocks.6.norm.weight', 'target_model.mamba_blocks.6.norm.bias', 'target_model.mamba_blocks.7.in_proj.weight', 'target_model.mamba_blocks.7.conv1d.weight', 'target_model.mamba_blocks.7.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.A_log', 'target_model.mamba_blocks.7.mamba_fwd.D', 'target_model.mamba_blocks.7.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.A_log', 'target_model.mamba_blocks.7.mamba_bwd.D', 'target_model.mamba_blocks.7.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.7.out_proj.weight', 'target_model.mamba_blocks.7.norm.weight', 'target_model.mamba_blocks.7.norm.bias', 'target_model.norm_f.weight', 'target_model.norm_f.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = \"finetune_weight/pretrain_epoch020.pt\"\n",
    "state_dict = torch.load(weight_path, map_location=DEVICE)\n",
    "model_state = state_dict[\"model_state\"]\n",
    "\n",
    "model.backbone.load_state_dict(model_state, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "107f2f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['cls_token', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'mamba_blocks.0.in_proj.weight', 'mamba_blocks.0.conv1d.weight', 'mamba_blocks.0.conv1d.bias', 'mamba_blocks.0.mamba_fwd.A_log', 'mamba_blocks.0.mamba_fwd.D', 'mamba_blocks.0.mamba_fwd.in_proj.weight', 'mamba_blocks.0.mamba_fwd.conv1d.weight', 'mamba_blocks.0.mamba_fwd.conv1d.bias', 'mamba_blocks.0.mamba_fwd.x_proj.weight', 'mamba_blocks.0.mamba_fwd.dt_proj.weight', 'mamba_blocks.0.mamba_fwd.dt_proj.bias', 'mamba_blocks.0.mamba_fwd.out_proj.weight', 'mamba_blocks.0.mamba_bwd.A_log', 'mamba_blocks.0.mamba_bwd.D', 'mamba_blocks.0.mamba_bwd.in_proj.weight', 'mamba_blocks.0.mamba_bwd.conv1d.weight', 'mamba_blocks.0.mamba_bwd.conv1d.bias', 'mamba_blocks.0.mamba_bwd.x_proj.weight', 'mamba_blocks.0.mamba_bwd.dt_proj.weight', 'mamba_blocks.0.mamba_bwd.dt_proj.bias', 'mamba_blocks.0.mamba_bwd.out_proj.weight', 'mamba_blocks.0.out_proj.weight', 'mamba_blocks.0.norm.weight', 'mamba_blocks.0.norm.bias', 'mamba_blocks.1.in_proj.weight', 'mamba_blocks.1.conv1d.weight', 'mamba_blocks.1.conv1d.bias', 'mamba_blocks.1.mamba_fwd.A_log', 'mamba_blocks.1.mamba_fwd.D', 'mamba_blocks.1.mamba_fwd.in_proj.weight', 'mamba_blocks.1.mamba_fwd.conv1d.weight', 'mamba_blocks.1.mamba_fwd.conv1d.bias', 'mamba_blocks.1.mamba_fwd.x_proj.weight', 'mamba_blocks.1.mamba_fwd.dt_proj.weight', 'mamba_blocks.1.mamba_fwd.dt_proj.bias', 'mamba_blocks.1.mamba_fwd.out_proj.weight', 'mamba_blocks.1.mamba_bwd.A_log', 'mamba_blocks.1.mamba_bwd.D', 'mamba_blocks.1.mamba_bwd.in_proj.weight', 'mamba_blocks.1.mamba_bwd.conv1d.weight', 'mamba_blocks.1.mamba_bwd.conv1d.bias', 'mamba_blocks.1.mamba_bwd.x_proj.weight', 'mamba_blocks.1.mamba_bwd.dt_proj.weight', 'mamba_blocks.1.mamba_bwd.dt_proj.bias', 'mamba_blocks.1.mamba_bwd.out_proj.weight', 'mamba_blocks.1.out_proj.weight', 'mamba_blocks.1.norm.weight', 'mamba_blocks.1.norm.bias', 'mamba_blocks.2.in_proj.weight', 'mamba_blocks.2.conv1d.weight', 'mamba_blocks.2.conv1d.bias', 'mamba_blocks.2.mamba_fwd.A_log', 'mamba_blocks.2.mamba_fwd.D', 'mamba_blocks.2.mamba_fwd.in_proj.weight', 'mamba_blocks.2.mamba_fwd.conv1d.weight', 'mamba_blocks.2.mamba_fwd.conv1d.bias', 'mamba_blocks.2.mamba_fwd.x_proj.weight', 'mamba_blocks.2.mamba_fwd.dt_proj.weight', 'mamba_blocks.2.mamba_fwd.dt_proj.bias', 'mamba_blocks.2.mamba_fwd.out_proj.weight', 'mamba_blocks.2.mamba_bwd.A_log', 'mamba_blocks.2.mamba_bwd.D', 'mamba_blocks.2.mamba_bwd.in_proj.weight', 'mamba_blocks.2.mamba_bwd.conv1d.weight', 'mamba_blocks.2.mamba_bwd.conv1d.bias', 'mamba_blocks.2.mamba_bwd.x_proj.weight', 'mamba_blocks.2.mamba_bwd.dt_proj.weight', 'mamba_blocks.2.mamba_bwd.dt_proj.bias', 'mamba_blocks.2.mamba_bwd.out_proj.weight', 'mamba_blocks.2.out_proj.weight', 'mamba_blocks.2.norm.weight', 'mamba_blocks.2.norm.bias', 'mamba_blocks.3.in_proj.weight', 'mamba_blocks.3.conv1d.weight', 'mamba_blocks.3.conv1d.bias', 'mamba_blocks.3.mamba_fwd.A_log', 'mamba_blocks.3.mamba_fwd.D', 'mamba_blocks.3.mamba_fwd.in_proj.weight', 'mamba_blocks.3.mamba_fwd.conv1d.weight', 'mamba_blocks.3.mamba_fwd.conv1d.bias', 'mamba_blocks.3.mamba_fwd.x_proj.weight', 'mamba_blocks.3.mamba_fwd.dt_proj.weight', 'mamba_blocks.3.mamba_fwd.dt_proj.bias', 'mamba_blocks.3.mamba_fwd.out_proj.weight', 'mamba_blocks.3.mamba_bwd.A_log', 'mamba_blocks.3.mamba_bwd.D', 'mamba_blocks.3.mamba_bwd.in_proj.weight', 'mamba_blocks.3.mamba_bwd.conv1d.weight', 'mamba_blocks.3.mamba_bwd.conv1d.bias', 'mamba_blocks.3.mamba_bwd.x_proj.weight', 'mamba_blocks.3.mamba_bwd.dt_proj.weight', 'mamba_blocks.3.mamba_bwd.dt_proj.bias', 'mamba_blocks.3.mamba_bwd.out_proj.weight', 'mamba_blocks.3.out_proj.weight', 'mamba_blocks.3.norm.weight', 'mamba_blocks.3.norm.bias', 'mamba_blocks.4.in_proj.weight', 'mamba_blocks.4.conv1d.weight', 'mamba_blocks.4.conv1d.bias', 'mamba_blocks.4.mamba_fwd.A_log', 'mamba_blocks.4.mamba_fwd.D', 'mamba_blocks.4.mamba_fwd.in_proj.weight', 'mamba_blocks.4.mamba_fwd.conv1d.weight', 'mamba_blocks.4.mamba_fwd.conv1d.bias', 'mamba_blocks.4.mamba_fwd.x_proj.weight', 'mamba_blocks.4.mamba_fwd.dt_proj.weight', 'mamba_blocks.4.mamba_fwd.dt_proj.bias', 'mamba_blocks.4.mamba_fwd.out_proj.weight', 'mamba_blocks.4.mamba_bwd.A_log', 'mamba_blocks.4.mamba_bwd.D', 'mamba_blocks.4.mamba_bwd.in_proj.weight', 'mamba_blocks.4.mamba_bwd.conv1d.weight', 'mamba_blocks.4.mamba_bwd.conv1d.bias', 'mamba_blocks.4.mamba_bwd.x_proj.weight', 'mamba_blocks.4.mamba_bwd.dt_proj.weight', 'mamba_blocks.4.mamba_bwd.dt_proj.bias', 'mamba_blocks.4.mamba_bwd.out_proj.weight', 'mamba_blocks.4.out_proj.weight', 'mamba_blocks.4.norm.weight', 'mamba_blocks.4.norm.bias', 'mamba_blocks.5.in_proj.weight', 'mamba_blocks.5.conv1d.weight', 'mamba_blocks.5.conv1d.bias', 'mamba_blocks.5.mamba_fwd.A_log', 'mamba_blocks.5.mamba_fwd.D', 'mamba_blocks.5.mamba_fwd.in_proj.weight', 'mamba_blocks.5.mamba_fwd.conv1d.weight', 'mamba_blocks.5.mamba_fwd.conv1d.bias', 'mamba_blocks.5.mamba_fwd.x_proj.weight', 'mamba_blocks.5.mamba_fwd.dt_proj.weight', 'mamba_blocks.5.mamba_fwd.dt_proj.bias', 'mamba_blocks.5.mamba_fwd.out_proj.weight', 'mamba_blocks.5.mamba_bwd.A_log', 'mamba_blocks.5.mamba_bwd.D', 'mamba_blocks.5.mamba_bwd.in_proj.weight', 'mamba_blocks.5.mamba_bwd.conv1d.weight', 'mamba_blocks.5.mamba_bwd.conv1d.bias', 'mamba_blocks.5.mamba_bwd.x_proj.weight', 'mamba_blocks.5.mamba_bwd.dt_proj.weight', 'mamba_blocks.5.mamba_bwd.dt_proj.bias', 'mamba_blocks.5.mamba_bwd.out_proj.weight', 'mamba_blocks.5.out_proj.weight', 'mamba_blocks.5.norm.weight', 'mamba_blocks.5.norm.bias', 'mamba_blocks.6.in_proj.weight', 'mamba_blocks.6.conv1d.weight', 'mamba_blocks.6.conv1d.bias', 'mamba_blocks.6.mamba_fwd.A_log', 'mamba_blocks.6.mamba_fwd.D', 'mamba_blocks.6.mamba_fwd.in_proj.weight', 'mamba_blocks.6.mamba_fwd.conv1d.weight', 'mamba_blocks.6.mamba_fwd.conv1d.bias', 'mamba_blocks.6.mamba_fwd.x_proj.weight', 'mamba_blocks.6.mamba_fwd.dt_proj.weight', 'mamba_blocks.6.mamba_fwd.dt_proj.bias', 'mamba_blocks.6.mamba_fwd.out_proj.weight', 'mamba_blocks.6.mamba_bwd.A_log', 'mamba_blocks.6.mamba_bwd.D', 'mamba_blocks.6.mamba_bwd.in_proj.weight', 'mamba_blocks.6.mamba_bwd.conv1d.weight', 'mamba_blocks.6.mamba_bwd.conv1d.bias', 'mamba_blocks.6.mamba_bwd.x_proj.weight', 'mamba_blocks.6.mamba_bwd.dt_proj.weight', 'mamba_blocks.6.mamba_bwd.dt_proj.bias', 'mamba_blocks.6.mamba_bwd.out_proj.weight', 'mamba_blocks.6.out_proj.weight', 'mamba_blocks.6.norm.weight', 'mamba_blocks.6.norm.bias', 'mamba_blocks.7.in_proj.weight', 'mamba_blocks.7.conv1d.weight', 'mamba_blocks.7.conv1d.bias', 'mamba_blocks.7.mamba_fwd.A_log', 'mamba_blocks.7.mamba_fwd.D', 'mamba_blocks.7.mamba_fwd.in_proj.weight', 'mamba_blocks.7.mamba_fwd.conv1d.weight', 'mamba_blocks.7.mamba_fwd.conv1d.bias', 'mamba_blocks.7.mamba_fwd.x_proj.weight', 'mamba_blocks.7.mamba_fwd.dt_proj.weight', 'mamba_blocks.7.mamba_fwd.dt_proj.bias', 'mamba_blocks.7.mamba_fwd.out_proj.weight', 'mamba_blocks.7.mamba_bwd.A_log', 'mamba_blocks.7.mamba_bwd.D', 'mamba_blocks.7.mamba_bwd.in_proj.weight', 'mamba_blocks.7.mamba_bwd.conv1d.weight', 'mamba_blocks.7.mamba_bwd.conv1d.bias', 'mamba_blocks.7.mamba_bwd.x_proj.weight', 'mamba_blocks.7.mamba_bwd.dt_proj.weight', 'mamba_blocks.7.mamba_bwd.dt_proj.bias', 'mamba_blocks.7.mamba_bwd.out_proj.weight', 'mamba_blocks.7.out_proj.weight', 'mamba_blocks.7.norm.weight', 'mamba_blocks.7.norm.bias', 'norm_f.weight', 'norm_f.bias', 'target_model.cls_token', 'target_model.patch_embed.proj.weight', 'target_model.patch_embed.proj.bias', 'target_model.mamba_blocks.0.in_proj.weight', 'target_model.mamba_blocks.0.conv1d.weight', 'target_model.mamba_blocks.0.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.A_log', 'target_model.mamba_blocks.0.mamba_fwd.D', 'target_model.mamba_blocks.0.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.A_log', 'target_model.mamba_blocks.0.mamba_bwd.D', 'target_model.mamba_blocks.0.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.0.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.0.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.0.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.0.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.0.out_proj.weight', 'target_model.mamba_blocks.0.norm.weight', 'target_model.mamba_blocks.0.norm.bias', 'target_model.mamba_blocks.1.in_proj.weight', 'target_model.mamba_blocks.1.conv1d.weight', 'target_model.mamba_blocks.1.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.A_log', 'target_model.mamba_blocks.1.mamba_fwd.D', 'target_model.mamba_blocks.1.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.A_log', 'target_model.mamba_blocks.1.mamba_bwd.D', 'target_model.mamba_blocks.1.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.1.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.1.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.1.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.1.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.1.out_proj.weight', 'target_model.mamba_blocks.1.norm.weight', 'target_model.mamba_blocks.1.norm.bias', 'target_model.mamba_blocks.2.in_proj.weight', 'target_model.mamba_blocks.2.conv1d.weight', 'target_model.mamba_blocks.2.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.A_log', 'target_model.mamba_blocks.2.mamba_fwd.D', 'target_model.mamba_blocks.2.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.A_log', 'target_model.mamba_blocks.2.mamba_bwd.D', 'target_model.mamba_blocks.2.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.2.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.2.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.2.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.2.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.2.out_proj.weight', 'target_model.mamba_blocks.2.norm.weight', 'target_model.mamba_blocks.2.norm.bias', 'target_model.mamba_blocks.3.in_proj.weight', 'target_model.mamba_blocks.3.conv1d.weight', 'target_model.mamba_blocks.3.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.A_log', 'target_model.mamba_blocks.3.mamba_fwd.D', 'target_model.mamba_blocks.3.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.A_log', 'target_model.mamba_blocks.3.mamba_bwd.D', 'target_model.mamba_blocks.3.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.3.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.3.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.3.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.3.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.3.out_proj.weight', 'target_model.mamba_blocks.3.norm.weight', 'target_model.mamba_blocks.3.norm.bias', 'target_model.mamba_blocks.4.in_proj.weight', 'target_model.mamba_blocks.4.conv1d.weight', 'target_model.mamba_blocks.4.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.A_log', 'target_model.mamba_blocks.4.mamba_fwd.D', 'target_model.mamba_blocks.4.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.A_log', 'target_model.mamba_blocks.4.mamba_bwd.D', 'target_model.mamba_blocks.4.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.4.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.4.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.4.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.4.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.4.out_proj.weight', 'target_model.mamba_blocks.4.norm.weight', 'target_model.mamba_blocks.4.norm.bias', 'target_model.mamba_blocks.5.in_proj.weight', 'target_model.mamba_blocks.5.conv1d.weight', 'target_model.mamba_blocks.5.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.A_log', 'target_model.mamba_blocks.5.mamba_fwd.D', 'target_model.mamba_blocks.5.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.A_log', 'target_model.mamba_blocks.5.mamba_bwd.D', 'target_model.mamba_blocks.5.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.5.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.5.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.5.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.5.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.5.out_proj.weight', 'target_model.mamba_blocks.5.norm.weight', 'target_model.mamba_blocks.5.norm.bias', 'target_model.mamba_blocks.6.in_proj.weight', 'target_model.mamba_blocks.6.conv1d.weight', 'target_model.mamba_blocks.6.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.A_log', 'target_model.mamba_blocks.6.mamba_fwd.D', 'target_model.mamba_blocks.6.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.A_log', 'target_model.mamba_blocks.6.mamba_bwd.D', 'target_model.mamba_blocks.6.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.6.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.6.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.6.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.6.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.6.out_proj.weight', 'target_model.mamba_blocks.6.norm.weight', 'target_model.mamba_blocks.6.norm.bias', 'target_model.mamba_blocks.7.in_proj.weight', 'target_model.mamba_blocks.7.conv1d.weight', 'target_model.mamba_blocks.7.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.A_log', 'target_model.mamba_blocks.7.mamba_fwd.D', 'target_model.mamba_blocks.7.mamba_fwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_fwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_fwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_fwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_fwd.out_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.A_log', 'target_model.mamba_blocks.7.mamba_bwd.D', 'target_model.mamba_blocks.7.mamba_bwd.in_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.weight', 'target_model.mamba_blocks.7.mamba_bwd.conv1d.bias', 'target_model.mamba_blocks.7.mamba_bwd.x_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.weight', 'target_model.mamba_blocks.7.mamba_bwd.dt_proj.bias', 'target_model.mamba_blocks.7.mamba_bwd.out_proj.weight', 'target_model.mamba_blocks.7.out_proj.weight', 'target_model.mamba_blocks.7.norm.weight', 'target_model.mamba_blocks.7.norm.bias', 'target_model.norm_f.weight', 'target_model.norm_f.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state = state_dict[\"model_state\"]\n",
    "model_state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c337832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
