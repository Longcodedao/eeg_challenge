python pretrain.py \
    --release R1 R2 R3 \
    --mini \
    --window-sec 6 \
    --epochs 10 \
    --warmup-epochs 2 \
    --batch-size 2048 \
    --lr 1e-4 \
    --momentum-decay 0.995 \
    --log-dir runs/ \
    --checkpoint-dir checkpoints/ \
    --checkpoint-interval 20 \
    --num-workers 4

    
# For full training (use --preprocess if needed)
python pretrain.py \
    --data-root MyNeurIPSData/MyNeurIPSData/HBN_DATA_FULL/ \
    --release R10 R11 \
    --window-sec 2 \
    --epochs 200 \
    --warmup-epochs 20 \
    --batch-size 2048 \
    --lr 1e-4 \
    --momentum-decay 0.995 \
    --log-dir runs/ \
    --checkpoint-dir checkpoints/ \
    --checkpoint-interval 20 \
    --num-workers 4

## Note that we have to have the big data to be able to preprocess so if you want to preprocess it 
## Set the download to True. Otherwise I will clean everything here for reducing the memory here 



# Download dataset option
# Download mini dataset (default)
python download_dataset.py

# Download full dataset
python download_dataset.py --mode full

# Custom configuration
python download_dataset.py --mode mini --base-path . --data-folder MyEEGData_mini 
python download_dataset.py --mode full --base-path . --data-folder MyEEGData_full 

# Use custom JSON file
python download_dataset.py --json-file my_custom_structure.json

# Force redownload existing data
python download_dataset.py --mode full --force-redownload

# Quiet mode (no progress bars)
python download_dataset.py --mode mini --quiet

# Custom chunk size for slower connections
python download_dataset.py --mode full --chunk-size 4096