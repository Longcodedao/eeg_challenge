{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbe225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "from tbparse import SummaryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8667480c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Val/backbone/MSE</td>\n",
       "      <td>0.639654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Val/backbone/MSE</td>\n",
       "      <td>0.601093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Val/backbone/RMSE</td>\n",
       "      <td>0.799750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Val/backbone/RMSE</td>\n",
       "      <td>0.775275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>backbone/Active_Mixtures</td>\n",
       "      <td>2.993335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step                       tag     value\n",
       "0     1          Val/backbone/MSE  0.639654\n",
       "1     2          Val/backbone/MSE  0.601093\n",
       "2     1         Val/backbone/RMSE  0.799750\n",
       "3     2         Val/backbone/RMSE  0.775275\n",
       "4     1  backbone/Active_Mixtures  2.993335"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR_1 = \"logs/finetune_challenge2_1762157150/events.out.tfevents.1762157150.93588e1400d5.17321.0\"\n",
    "\n",
    "reader = SummaryReader(LOG_DIR_1)\n",
    "df = reader.scalars\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3640d0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Val/backbone/MSE</th>\n",
       "      <th>Val/backbone/RMSE</th>\n",
       "      <th>backbone/Active_Mixtures</th>\n",
       "      <th>backbone/LR</th>\n",
       "      <th>backbone/MDN_Loss</th>\n",
       "      <th>backbone/MSE</th>\n",
       "      <th>backbone/RMSE</th>\n",
       "      <th>backbone/π_Entropy</th>\n",
       "      <th>backbone/π_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639654</td>\n",
       "      <td>0.799750</td>\n",
       "      <td>2.993335</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1.168489</td>\n",
       "      <td>0.545115</td>\n",
       "      <td>0.738296</td>\n",
       "      <td>1.036734</td>\n",
       "      <td>0.463129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>0.775275</td>\n",
       "      <td>2.881944</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.962732</td>\n",
       "      <td>0.475892</td>\n",
       "      <td>0.689637</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.582579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Val/backbone/MSE  Val/backbone/RMSE  backbone/Active_Mixtures  \\\n",
       "0      1          0.639654           0.799750                  2.993335   \n",
       "1      2          0.601093           0.775275                  2.881944   \n",
       "\n",
       "   backbone/LR  backbone/MDN_Loss  backbone/MSE  backbone/RMSE  \\\n",
       "0      0.00002           1.168489      0.545115       0.738296   \n",
       "1      0.00004           0.962732      0.475892       0.689637   \n",
       "\n",
       "   backbone/π_Entropy  backbone/π_Max  \n",
       "0            1.036734        0.463129  \n",
       "1            0.927527        0.582579  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df['tag'].unique().tolist()\n",
    "index = df['step'].unique().tolist()\n",
    "\n",
    "data = {col: [] for col in columns}\n",
    "for step in index:\n",
    "    step_data = df[df['step'] == step]\n",
    "    for col in columns:\n",
    "\n",
    "        value = step_data[step_data['tag'] == col]['value']\n",
    "        if not value.empty:\n",
    "            data[col].append(value.values[0])\n",
    "        else:\n",
    "            data[col].append(None)\n",
    "# ensure 'Epoch' is the first column\n",
    "data.pop('Epoch', None)\n",
    "data = {'Epoch': index, **data}\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837a6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Epoch                     2 non-null      int64  \n",
      " 1   Val/backbone/MSE          2 non-null      float64\n",
      " 2   Val/backbone/RMSE         2 non-null      float64\n",
      " 3   backbone/Active_Mixtures  2 non-null      float64\n",
      " 4   backbone/LR               2 non-null      float64\n",
      " 5   backbone/MDN_Loss         2 non-null      float64\n",
      " 6   backbone/MSE              2 non-null      float64\n",
      " 7   backbone/RMSE             2 non-null      float64\n",
      " 8   backbone/π_Entropy        2 non-null      float64\n",
      " 9   backbone/π_Max            2 non-null      float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 292.0 bytes\n"
     ]
    }
   ],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb8365",
   "metadata": {},
   "source": [
    "## EDA the lenghth of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1eaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from eegdash.dataset import EEGChallengeDataset\n",
    "from braindecode.datasets.base import EEGWindowsDataset, BaseConcatDataset, BaseDataset\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_windows_from_events\n",
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "\n",
    "import torch\n",
    "from model.meta_encoder import MetaEncoder\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0dd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFREQ = 100\n",
    "CROP_SEC = 2\n",
    "WINDOW_SEC = 4\n",
    "STRIDE_SEC = 2\n",
    "DESCRIPTION_FILEDS = [\n",
    "    \"subject\", \"session\", \"run\", \"task\", \"age\", \"gender\", \"sex\", \"p_factor\"\n",
    "]\n",
    "TASK_NAMES = [\n",
    "    \"RestingState\", \"DespicableMe\", \"DiaryOfAWimpyKid\", \"FunwithFractals\",\n",
    "    \"ThePresent\", \"contrastChangeDetection\", \"seqLearning6target\",\n",
    "    \"seqLearning8target\", \"surroundSupp\", \"symbolSearch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb08690",
   "metadata": {},
   "source": [
    "CropWrapper Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ab63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropMetaWrapper(BaseDataset):\n",
    "    def __init__(self, windows_ds, \n",
    "                        crop_samples, \n",
    "                        meta_encoder, \n",
    "                        target_name=\"externalizing\"):\n",
    "        \n",
    "        self.windows_ds = windows_ds\n",
    "        self.crop_samples = crop_samples\n",
    "        self.meta_encoder = meta_encoder\n",
    "        self.target_name = target_name\n",
    "        self.rng = np.random.default_rng(2025)  # fixed seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows_ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, _, crop_inds = self.windows_ds[idx]  # X: (C, 4*SFREQ)\n",
    "\n",
    "        # Target\n",
    "        target = float(self.windows_ds.description[self.target_name])\n",
    "\n",
    "        # Meta\n",
    "        desc = self.windows_ds.description\n",
    "        meta_dict = {\n",
    "            \"task\": desc[\"task\"],\n",
    "            \"sex\": desc[\"sex\"],\n",
    "            \"age\": float(desc[\"age\"]),\n",
    "        }\n",
    "        meta_vec = self.meta_encoder.transform(meta_dict)\n",
    "\n",
    "        # Random 2s crop\n",
    "        i_win, i_start, i_stop = crop_inds\n",
    "\n",
    "\n",
    "        assert i_stop - i_start >= self.crop_samples\n",
    "\n",
    "        # FIXED: .integers instead of .randint\n",
    "        offset = self.rng.integers(0, i_stop - i_start - self.crop_samples + 1)\n",
    "        i_start = i_start + offset\n",
    "        i_stop = i_start + self.crop_samples\n",
    "        X_crop = X[:, offset : offset + self.crop_samples]  # (C, 2*SFREQ)\n",
    "\n",
    "        # Infos\n",
    "        infos = {\n",
    "            \"subject\": desc[\"subject\"],\n",
    "            \"session\": desc.get(\"session\", \"\"),\n",
    "            \"run\": desc.get(\"run\", \"\"),\n",
    "            \"task\": desc[\"task\"],\n",
    "            \"sex\": desc[\"sex\"],\n",
    "            \"age\": float(desc[\"age\"]),\n",
    "        }\n",
    "\n",
    "        return torch.tensor(X_crop), meta_vec, target, (i_win, i_start, i_stop), infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e66dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subdatasets = []\n",
    "meta_encoder = []\n",
    "\n",
    "RELEASE = [f\"R{i}\" for i in range(1, 12)]\n",
    "data_root = Path('MyEEGData_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e14657e",
   "metadata": {},
   "source": [
    "Load the joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9920e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess_data/challenge2/R5_windows_task[RestingState].pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Successfully loaded windows from preprocess_data/challenge2/R5_windows_task[RestingState].pkl\n"
     ]
    }
   ],
   "source": [
    "release = \"R5\"\n",
    "task = \"RestingState\"\n",
    "\n",
    "preproc_root = Path('preprocess_data/challenge2')\n",
    "preproc_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "load_path = preproc_root / f\"{release}_windows_task[{task}].pkl\"\n",
    "print(load_path)\n",
    "\n",
    "list_windows = []\n",
    "try: \n",
    "    windows_ds = joblib.load(load_path)\n",
    "    list_windows.append(windows_ds)\n",
    "    print(f\"  -> Successfully loaded windows from {load_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"  -> FAILED to load windows from {load_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f1fc9",
   "metadata": {},
   "source": [
    "Uploading the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c2bff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf99c718df444fe9b60fbd66fd4f186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading preprocessed windows:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows dataset size: 447063\n"
     ]
    }
   ],
   "source": [
    "list_windows = []\n",
    "\n",
    "RELEASE = ['R5']\n",
    "total = len(RELEASE) * len(TASK_NAMES)\n",
    "pbar = tqdm(total=total, desc = \"Loading preprocessed windows\")\n",
    "\n",
    "for release in RELEASE:\n",
    "    for task in TASK_NAMES:\n",
    "\n",
    "        load_path = preproc_root / f\"{release}_windows_task[{task}].pkl\"\n",
    "        try:\n",
    "            windows_ds = joblib.load(load_path)\n",
    "            list_windows.append(windows_ds)\n",
    "        except Exception as e:\n",
    "            print(f\"  -> FAILED to load windows from {load_path}: {e}\")\n",
    "        finally:\n",
    "            pbar.update(1)\n",
    "            \n",
    "pbar.close()\n",
    "all_windows_ds = BaseConcatDataset(list_windows)\n",
    "print(f\"Total windows dataset size: {len(all_windows_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a94c6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subjects = []\n",
    "for i in range(len(all_windows_ds.datasets)):\n",
    "    subject = all_windows_ds.datasets[i].windows_ds.description['subject']\n",
    "    list_subjects.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit the subject \n",
    "unique_subjects = list(set(list_subjects))\n",
    "\n",
    "total_length = len(unique_subjects)\n",
    "train_size = int(0.8 * total_length)\n",
    "val_size = total_length - train_size\n",
    "\n",
    "train_subjects = unique_subjects[: train_size]\n",
    "val_subjects = unique_subjects[train_size : ]\n",
    "\n",
    "print(f\"Total subjects: {len(unique_subjects)}\")\n",
    "print(f\"Train subjects: {len(train_subjects)}\")\n",
    "print(f\"Validation subjects: {len(val_subjects)}\")\n",
    "\n",
    "train_datasets = []\n",
    "val_datasets = []\n",
    "\n",
    "for ds in all_windows_ds.datasets:\n",
    "    subject = ds.windows_ds.description['subject']\n",
    "    if subject in train_subjects:\n",
    "        train_datasets.append(ds)\n",
    "    elif subject in val_subjects:\n",
    "        val_datasets.append(ds)\n",
    "\n",
    "train_window_data = BaseConcatDataset(train_datasets)\n",
    "val_window_data = BaseConcatDataset(val_datasets)\n",
    "len_train = len(train_window_data)\n",
    "len_val = len(val_window_data)\n",
    "\n",
    "print(f\"Train windows: {len_train}\")\n",
    "print(f\"Validation windows: {len_val}\")\n",
    "assert len_train + len_val == len(all_windows_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b246d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit the subject \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "unique_subjects = list(set(list_subjects))\n",
    "\n",
    "total_length = len(unique_subjects)\n",
    "train_size = int(0.8 * total_length)\n",
    "val_size = int(0.1 * total_length)\n",
    "test_size = total_length - train_size - val_size\n",
    "seed = 2005\n",
    "\n",
    "train_subj, val_test_subj = train_test_split(\n",
    "    unique_subjects, train_size=train_size, test_size=val_size + test_size, random_state=seed\n",
    ")\n",
    "\n",
    "val_subj, test_subj = train_test_split(\n",
    "    val_test_subj, train_size=val_size, test_size=test_size, random_state=seed\n",
    ")\n",
    "\n",
    "def split_by_subjects(dataset, subject_list):\n",
    "    indices = []\n",
    "    for ds in dataset.datasets:\n",
    "        subject = ds.windows_ds.description['subject']\n",
    "        if subject in subject_list:\n",
    "            indices.append(ds)\n",
    "\n",
    "    return BaseConcatDataset(indices)\n",
    "\n",
    "train_set = split_by_subjects(all_windows_ds, train_subj)\n",
    "val_set = split_by_subjects(all_windows_ds, val_subj)\n",
    "test_set = split_by_subjects(all_windows_ds, test_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4b45118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: 355181\n",
      "Validation windows: 45101\n",
      "Test windows: 46781\n",
      "Total windows: 447063\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train windows: {len(train_set)}\")\n",
    "print(f\"Validation windows: {len(val_set)}\")\n",
    "print(f\"Test windows: {len(test_set)}\")\n",
    "\n",
    "print(f\"Total windows: {len(train_set) + len(val_set) + len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e435ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sample1 = train_window_data[0]\n",
    "X, meta_vec, target, crop_inds, infos = xtrain_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f84666e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: 52885\n",
      "Validation windows: 13422\n"
     ]
    }
   ],
   "source": [
    "train_window_data = BaseConcatDataset(train_datasets)\n",
    "val_window_data = BaseConcatDataset(val_datasets)\n",
    "\n",
    "print(f\"Train windows: {len(train_window_data)}\")\n",
    "print(f\"Validation windows: {len(val_window_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7123fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample1 = train_window_data[0]\n",
    "X, meta_vec, target, crop_inds, infos = train_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127defe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
